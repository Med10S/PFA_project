{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd3e524e",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Entra√Ænement du mod√®le MLP avec la m√©thode exacte du notebook pasteCode.ipynb\n",
    "Utilise l'entra√Ænement progressif pr√©f√©r√© par l'utilisateur\n",
    "Produit un mod√®le compatible avec le syst√®me (42 features, nom correct)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899bf23a",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Ce bloc de code importe les biblioth√®ques n√©cessaires pour l'analyse de donn√©es, la visualisation, le machine learning et la gestion des fichiers. Il configure √©galement la gestion des avertissements et cr√©e des r√©pertoires pour stocker les r√©sultats et les mod√®les.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61a02f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import time\n",
    "import winsound\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, log_loss, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from training_code.utils import load_and_preprocess_data,plot_training_metrics\n",
    "\n",
    "# Supprimer les avertissements non n√©cessaires\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "# Cr√©ation des dossiers pour les r√©sultats\n",
    "os.makedirs('figures/mlp', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb1238d",
   "metadata": {},
   "source": [
    "Ce bloc de code d√©finit une fonction nomm√©e `optimize_mlp_hyperparameters` qui optimise les hyperparam√®tres d'un mod√®le de r√©seau de neurones perceptron multicouche (MLP) √† l'aide d'une recherche al√©atoire avec validation crois√©e. Voici les √©tapes cl√©s r√©alis√©es par cette fonction :\n",
    "\n",
    "1.  **D√©finition de l'espace de recherche des hyperparam√®tres :**\n",
    "    *   D√©finit une grille de recherche (`param_dist`) contenant diff√©rents hyperparam√®tres √† optimiser, tels que le nombre de neurones dans les couches cach√©es (`hidden_layer_sizes`), la fonction d'activation (`activation`), le solveur d'optimisation (`solver`), le taux d'apprentissage (`learning_rate`) et le terme de r√©gularisation L2 (`alpha`).\n",
    "2.  **Initialisation du mod√®le MLP :**\n",
    "    *   Cr√©e une instance du mod√®le `MLPClassifier` avec des param√®tres par d√©faut, tels que le nombre maximal d'it√©rations (`max_iter`), l'arr√™t pr√©coce (`early_stopping`) et une graine al√©atoire (`random_state`).\n",
    "3.  **Recherche al√©atoire avec validation crois√©e :**\n",
    "    *   Utilise `RandomizedSearchCV` pour effectuer une recherche al√©atoire des meilleurs hyperparam√®tres en utilisant la validation crois√©e.\n",
    "    *   √âvalue les performances du mod√®le avec diff√©rentes combinaisons d'hyperparam√®tres en utilisant la m√©trique de score sp√©cifi√©e (pr√©cision).\n",
    "4.  **Entra√Ænement et √©valuation du mod√®le :**\n",
    "    *   Entra√Æne le mod√®le sur les donn√©es d'entra√Ænement avec les meilleurs hyperparam√®tres trouv√©s.\n",
    "    *   Calcule le score de pr√©cision sur l'ensemble de validation.\n",
    "5.  **Affichage des r√©sultats :**\n",
    "    *   Affiche les meilleurs hyperparam√®tres trouv√©s, le score de validation crois√©e et le score sur l'ensemble de validation.\n",
    "6.  **Retour des r√©sultats :**\n",
    "    *   Retourne les meilleurs hyperparam√®tres et le score de validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04c4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def optimize_mlp_hyperparameters(X_train, y_train, X_val, y_val, cv=3):\n",
    "    \"\"\"\n",
    "    Optimise les hyperparam√®tres du mod√®le MLP\n",
    "    EXACTEMENT comme dans pasteCode.ipynb\n",
    "    \"\"\"\n",
    "    print(f\"Optimisation des hyperparam√®tres MLP...\")\n",
    "    \n",
    "    param_dist = {\n",
    "        'hidden_layer_sizes': [(64,), (128,), (64, 32), (128, 64)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'solver': ['adam', 'sgd'],\n",
    "        'alpha': [0.0001, 0.001],\n",
    "        'learning_rate': ['constant', 'adaptive']\n",
    "    }\n",
    "\n",
    "    mlp = MLPClassifier(max_iter=200, early_stopping=True, random_state=42)\n",
    "    grid_search = RandomizedSearchCV(\n",
    "        mlp, param_distributions=param_dist, n_iter=15, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    search_time = time.time() - start_time\n",
    "    print(f\"Recherche par grille termin√©e en {search_time:.2f} secondes\")\n",
    "\n",
    "    val_score = accuracy_score(y_val, grid_search.predict(X_val))\n",
    "    print(f\"Meilleurs hyperparam√®tres: {grid_search.best_params_}\")\n",
    "    print(f\"Score de validation crois√©e: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Score sur l'ensemble de validation: {val_score:.4f}\")\n",
    "\n",
    "    return grid_search.best_params_, val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb447f",
   "metadata": {},
   "source": [
    "Ce bloc de code d√©finit une fonction nomm√©e `train_mlp_progressive` qui entra√Æne un mod√®le de r√©seau de neurones perceptron multicouche (MLP) de mani√®re progressive. L'entra√Ænement progressif signifie que la taille de l'ensemble d'entra√Ænement augmente √† chaque √©poque. Voici les √©tapes cl√©s r√©alis√©es par cette fonction :\n",
    "\n",
    "1.  **Initialisation :**\n",
    "    *   Convertit les ensembles de donn√©es en tableaux NumPy pour faciliter l'indexation.\n",
    "    *   V√©rifie si les ensembles d'entra√Ænement sont vides ou s'ils contiennent moins de deux classes, ce qui entra√Ænerait une erreur.\n",
    "    *   Initialise des listes pour stocker les m√©triques d'entra√Ænement et de validation (pr√©cision, perte, score F1 et rappel) pour chaque √©poque.\n",
    "    *   Initialise le mod√®le MLP avec les meilleurs hyperparam√®tres trouv√©s lors de l'optimisation.\n",
    "    *   D√©finit les valeurs de d√©but et de fin pour l'augmentation progressive de la taille de l'ensemble d'entra√Ænement.\n",
    "    *   Cr√©e un dictionnaire pour stocker les indices de chaque classe dans l'ensemble d'entra√Ænement, afin d'assurer une r√©partition √©quilibr√©e des classes lors de l'√©chantillonnage.\n",
    "2.  **Entra√Ænement progressif :**\n",
    "    *   It√®re sur le nombre d'√©poques sp√©cifi√©.\n",
    "    *   √Ä chaque √©poque, calcule la taille de l'ensemble d'entra√Ænement en fonction de la progression lin√©aire d√©finie par les valeurs de d√©but et de fin.\n",
    "    *   √âchantillonne al√©atoirement les donn√©es d'entra√Ænement en assurant une r√©partition √©quilibr√©e des classes.\n",
    "    *   Entra√Æne le mod√®le sur les donn√©es d'entra√Ænement √©chantillonn√©es.\n",
    "    *   √âvalue les performances du mod√®le sur les ensembles d'entra√Ænement et de validation en calculant la pr√©cision, la perte, le score F1 et le rappel.\n",
    "    *   Stocke les m√©triques dans les listes correspondantes.\n",
    "    *   Suit le meilleur mod√®le en fonction de la pr√©cision sur l'ensemble de validation.\n",
    "3.  **Gestion des erreurs :**\n",
    "    *   G√®re les erreurs potentielles lors de l'entra√Ænement et de l'√©valuation du mod√®le.\n",
    "    *   Si aucune donn√©e valide n'est trouv√©e pendant l'entra√Ænement, un mod√®le par d√©faut est cr√©√© et entra√Æn√©.\n",
    "4.  **Visualisation des r√©sultats :**\n",
    "    *   Trace les m√©triques d'entra√Ænement et de validation en utilisant la fonction `plot_training_metrics`.\n",
    "    *   Trace la progression de la taille de l'ensemble d'entra√Ænement au fil des √©poques.\n",
    "    *   Trace la matrice de confusion pour le meilleur mod√®le sur l'ensemble de test.\n",
    "5.  **√âvaluation finale :**\n",
    "    *   √âvalue les performances du meilleur mod√®le sur l'ensemble de test en calculant la pr√©cision, le score F1 et le rappel.\n",
    "    *   Affiche les r√©sultats finaux.\n",
    "6.  **Sauvegarde du mod√®le :**\n",
    "    *   Sauvegarde le meilleur mod√®le dans un fichier.\n",
    "7.  **Retour des r√©sultats :**\n",
    "    *   Retourne un dictionnaire contenant les informations d'apprentissage, les m√©triques et le meilleur mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaf1ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_mlp_progressive(X_train, y_train, X_val, y_val, X_test, y_test, best_params, n_epochs=25):\n",
    "    \"\"\"\n",
    "    Entra√Æne le mod√®le MLP de mani√®re progressive en augmentant la taille de l'ensemble d'entra√Ænement\n",
    "    EXACTEMENT comme dans pasteCode.ipynb avec l'entra√Ænement progressif pr√©f√©r√©\n",
    "    \"\"\"\n",
    "    print(f\"Entra√Ænement progressif du MLP sur {n_epochs} √©poques...\")\n",
    "\n",
    "    # Convertir en tableaux NumPy pour √©viter les probl√®mes d'indexation\n",
    "    if not isinstance(X_train, np.ndarray):\n",
    "        X_train = np.array(X_train)\n",
    "    if not isinstance(y_train, np.ndarray):\n",
    "        y_train = np.array(y_train)\n",
    "    if not isinstance(X_val, np.ndarray):\n",
    "        X_val = np.array(X_val)\n",
    "    if not isinstance(y_val, np.ndarray):\n",
    "        y_val = np.array(y_val)\n",
    "    if not isinstance(X_test, np.ndarray):\n",
    "        X_test = np.array(X_test)\n",
    "    if not isinstance(y_test, np.ndarray):\n",
    "        y_test = np.array(y_test)\n",
    "\n",
    "    # V√©rifier si l'entra√Ænement est possible\n",
    "    if len(X_train) == 0 or len(y_train) == 0:\n",
    "        raise ValueError(\"Ensembles d'entra√Ænement vides\")\n",
    "    if len(np.unique(y_train)) < 2:\n",
    "        raise ValueError(\"L'ensemble d'entra√Ænement doit contenir au moins deux classes diff√©rentes\")\n",
    "\n",
    "    # M√©triques (EXACTEMENT comme dans le notebook)\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    train_precisions = []\n",
    "    val_precisions = []\n",
    "    train_recalls = []\n",
    "    val_recalls = []\n",
    "    train_f1s = []\n",
    "    val_f1s = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    epoch_train_sizes = []\n",
    "\n",
    "    # Initialiser le mod√®le avec les meilleurs param√®tres\n",
    "    model = MLPClassifier(**best_params, random_state=42)\n",
    "\n",
    "    # Meilleur mod√®le\n",
    "    best_model = None\n",
    "    best_val_acc = 0\n",
    "\n",
    "    # Valeurs pour l'augmentation progressive de la taille de l'ensemble d'entra√Ænement\n",
    "    train_ratio_start = 0.2  # Commence avec 20% des donn√©es\n",
    "    train_ratio_end = 1.0    # Termine avec 100% des donn√©es\n",
    "\n",
    "    # Assurer une r√©partition √©quilibr√©e des classes lors de l'√©chantillonnage\n",
    "    class_indices = {}\n",
    "    unique_classes = np.unique(y_train)\n",
    "    for cls in unique_classes:\n",
    "        class_indices[cls] = np.where(y_train == cls)[0]\n",
    "\n",
    "    with tqdm(total=n_epochs, desc=\"Entra√Ænement MLP\") as pbar:\n",
    "        for epoch in range(n_epochs):\n",
    "            try:\n",
    "                # Augmentation progressive de la taille de l'entra√Ænement\n",
    "                train_ratio = train_ratio_start + (train_ratio_end - train_ratio_start) * (epoch / max(1, n_epochs-1))\n",
    "                indices = []\n",
    "                for cls in unique_classes:\n",
    "                    n_samples = int(len(class_indices[cls]) * train_ratio)\n",
    "                    if n_samples > 0:\n",
    "                        cls_sample = np.random.choice(class_indices[cls], n_samples, replace=False)\n",
    "                        indices.extend(cls_sample)\n",
    "                np.random.shuffle(indices)\n",
    "                train_size = len(indices)\n",
    "                epoch_train_sizes.append(train_size)\n",
    "                \n",
    "                # Extraire les donn√©es d'entra√Ænement pour cette √©poque\n",
    "                X_epoch = X_train[indices]\n",
    "                y_epoch = y_train[indices]\n",
    "\n",
    "                # Cr√©er et entra√Æner le mod√®le avec les meilleurs hyperparam√®tres\n",
    "                model.fit(X_epoch, y_epoch)\n",
    "\n",
    "                # √âvaluations\n",
    "                train_pred = model.predict(X_epoch)\n",
    "                val_pred = model.predict(X_val)\n",
    "\n",
    "                train_acc = accuracy_score(y_epoch, train_pred)\n",
    "                val_acc = accuracy_score(y_val, val_pred)\n",
    "                train_prec = precision_score(y_epoch, train_pred, zero_division=0)\n",
    "                val_prec = precision_score(y_val, val_pred, zero_division=0)\n",
    "                train_rec = recall_score(y_epoch, train_pred, zero_division=0)\n",
    "                val_rec = recall_score(y_val, val_pred, zero_division=0)\n",
    "                train_f1 = f1_score(y_epoch, train_pred, zero_division=0)\n",
    "                val_f1 = f1_score(y_val, val_pred, zero_division=0)\n",
    "\n",
    "                train_accuracies.append(train_acc)\n",
    "                val_accuracies.append(val_acc)\n",
    "                train_precisions.append(train_prec)\n",
    "                val_precisions.append(val_prec)\n",
    "                train_recalls.append(train_rec)\n",
    "                val_recalls.append(val_rec)\n",
    "                train_f1s.append(train_f1)\n",
    "                val_f1s.append(val_f1)\n",
    "\n",
    "                # Calcul des pertes (log loss) si predict_proba est disponible\n",
    "                if hasattr(model, 'predict_proba'):\n",
    "                    try:\n",
    "                        train_probs = model.predict_proba(X_epoch)\n",
    "                        val_probs = model.predict_proba(X_val)\n",
    "                        # V√©rifier la validit√© des probabilit√©s\n",
    "                        if not np.any(np.isnan(train_probs)) and not np.any(np.isnan(val_probs)):\n",
    "                            train_loss = log_loss(y_epoch, train_probs)\n",
    "                            val_loss = log_loss(y_val, val_probs)\n",
    "                        else:\n",
    "                            train_loss = -np.log(max(0.001, train_acc))\n",
    "                            val_loss = -np.log(max(0.001, val_acc))\n",
    "                    except Exception:\n",
    "                        # En cas d'erreur, utiliser une approximation\n",
    "                        train_loss = -np.log(max(0.001, train_acc))\n",
    "                        val_loss = -np.log(max(0.001, val_acc))\n",
    "                else:\n",
    "                    # Si predict_proba n'est pas disponible, simuler une relation inverse avec l'accuracy\n",
    "                    train_loss = -np.log(max(0.001, train_acc))\n",
    "                    val_loss = -np.log(max(0.001, val_acc))\n",
    "\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\n",
    "                    'Train Acc': f'{train_acc:.4f}',\n",
    "                    'Val Acc': f'{val_acc:.4f}',\n",
    "                    'Train Size': train_size\n",
    "                })\n",
    "\n",
    "                # Suivre le meilleur mod√®le\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    best_model = model\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\nErreur √† l'√©poque {epoch+1}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    # Si aucun mod√®le valide n'a √©t√© trouv√©, utiliser un mod√®le par d√©faut\n",
    "    if best_model is None:\n",
    "        print(\"Aucun mod√®le valide trouv√© pendant l'entra√Ænement. Cr√©ation d'un mod√®le par d√©faut.\")\n",
    "        best_model = MLPClassifier(**best_params, random_state=42)\n",
    "        best_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Tracer les m√©triques d'entra√Ænement (EXACTEMENT comme dans le notebook)\n",
    "    try:\n",
    "        plot_training_metrics(train_accuracies, val_accuracies, train_losses, val_losses, \n",
    "                             train_f1s, val_f1s, train_recalls, val_recalls, n_epochs,\n",
    "                             algorithm_name=\"MLP\", output_dir=\"figures/mlp\")\n",
    "        \n",
    "        # Graphique de la taille de l'ensemble d'entra√Ænement\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(range(1, n_epochs+1), epoch_train_sizes, '-o', linewidth=2, markersize=4, color='#2ca02c')\n",
    "        plt.title('Progression de la taille de l\\'ensemble d\\'entra√Ænement', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('√âpoque', fontsize=12)\n",
    "        plt.ylabel('Nombre d\\'√©chantillons', fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('figures/mlp/mlp_training_size.png', dpi=300)\n",
    "        plt.close()\n",
    "        print(\"‚úÖ Graphique de progression de taille sauvegard√©\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la cr√©ation des graphiques: {str(e)}\")\n",
    "\n",
    "    # √âvaluation finale du meilleur mod√®le sur l'ensemble de test\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    test_precision = precision_score(y_test, test_pred, zero_division=0)\n",
    "    test_recall = recall_score(y_test, test_pred, zero_division=0)\n",
    "    test_f1 = f1_score(y_test, test_pred, zero_division=0)\n",
    "    conf_matrix = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "    # Tracer la matrice de confusion pour le meilleur mod√®le\n",
    "    try:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=['Normal', 'Attack'], yticklabels=['Normal', 'Attack'])\n",
    "        plt.title('Matrice de confusion MLP (Ensemble de test)', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Classe pr√©dite', fontsize=12)\n",
    "        plt.ylabel('Classe r√©elle', fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('figures/mlp/mlp_confusion_matrix.png', dpi=300)\n",
    "        plt.close()\n",
    "        print(\"‚úÖ Matrice de confusion sauvegard√©e\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la cr√©ation de la matrice de confusion: {str(e)}\")\n",
    "\n",
    "    # **CRITIQUE**: Sauvegarder avec le nom attendu par le syst√®me\n",
    "    try:\n",
    "        joblib.dump(best_model, \"models/mlp_best.pkl\")\n",
    "        print(\"‚úÖ Meilleur mod√®le MLP sauvegard√© dans models/mlp_best.pkl\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors de la sauvegarde du mod√®le: {str(e)}\")\n",
    "\n",
    "    # Afficher les r√©sultats finaux\n",
    "    print(\"\\n=== R√©sultats finaux ===\")\n",
    "    print(f\"Accuracy sur l'ensemble de test: {test_accuracy:.4f}\")\n",
    "    print(f\"Precision sur l'ensemble de test: {test_precision:.4f}\")\n",
    "    print(f\"Recall sur l'ensemble de test: {test_recall:.4f}\")\n",
    "    print(f\"F1-Score sur l'ensemble de test: {test_f1:.4f}\")\n",
    "    \n",
    "    # Analyser la matrice de confusion\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    total = tn + fp + fn + tp\n",
    "    print(f\"\\nD√©tail de la matrice de confusion:\")\n",
    "    print(f\"  - Vrais N√©gatifs (TN): {tn} ({tn/total*100:.2f}%)\")\n",
    "    print(f\"  - Faux Positifs (FP): {fp} ({fp/total*100:.2f}%)\")\n",
    "    print(f\"  - Faux N√©gatifs (FN): {fn} ({fn/total*100:.2f}%)\")\n",
    "    print(f\"  - Vrais Positifs (TP): {tp} ({tp/total*100:.2f}%)\")\n",
    "    print(f\"  - Taux de faux positifs: {fp/(fp+tn)*100:.2f}%\")\n",
    "    print(f\"  - Taux de faux n√©gatifs: {fn/(fn+tp)*100:.2f}%\")\n",
    "\n",
    "    # Retourner les informations d'apprentissage et le meilleur mod√®le\n",
    "    return {\n",
    "        'model': best_model,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_precisions': train_precisions,\n",
    "        'val_precisions': val_precisions,\n",
    "        'train_recalls': train_recalls,\n",
    "        'val_recalls': val_recalls,\n",
    "        'train_f1s': train_f1s,\n",
    "        'val_f1s': val_f1s,\n",
    "        'epoch_train_sizes': epoch_train_sizes,\n",
    "        'best_val_accuracy': best_val_acc,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'test_f1': test_f1,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65877e24",
   "metadata": {},
   "source": [
    "Ce bloc de code d√©finit la fonction principale `main` qui orchestre l'ensemble du pipeline d'entra√Ænement et d'√©valuation d'un mod√®le MLP (Multi-Layer Perceptron) pour la d√©tection d'intrusion r√©seau. Voici les √©tapes cl√©s r√©alis√©es par cette fonction :\n",
    "\n",
    "1.  **Initialisation :**\n",
    "    *   D√©finit les param√®tres par d√©faut pour le chemin du fichier de donn√©es, la taille des ensembles de test et de validation, le nombre d'√©poques et l'√©tat al√©atoire.\n",
    "    *   Affiche un message de bienvenue d√©crivant le pipeline.\n",
    "    *   Enregistre le temps de d√©but pour calculer la dur√©e totale d'ex√©cution.\n",
    "2.  **Chargement et pr√©traitement des donn√©es :**\n",
    "    *   Utilise la fonction `load_and_preprocess_data` pour charger, pr√©traiter et diviser les donn√©es en ensembles d'entra√Ænement, de validation et de test.\n",
    "    *   Sauvegarde le scaler et les encodeurs de labels pour une utilisation ult√©rieure.\n",
    "3.  **Optimisation des hyperparam√®tres :**\n",
    "    *   Utilise les meilleurs hyperparam√®tres pr√©d√©finis ou permet de lancer une optimisation des hyperparam√®tres en utilisant la fonction `optimize_mlp_hyperparameters` (cette partie est comment√©e par d√©faut).\n",
    "4.  **Entra√Ænement du mod√®le :**\n",
    "    *   Entra√Æne le mod√®le MLP en utilisant la fonction `train_mlp_progressive` avec les meilleurs hyperparam√®tres et les ensembles de donn√©es pr√©trait√©s.\n",
    "5.  **√âvaluation du mod√®le :**\n",
    "    *   √âvalue les performances du mod√®le entra√Æn√© sur l'ensemble de test en calculant la pr√©cision, le rappel, le score F1 et la matrice de confusion.\n",
    "    *   Affiche un r√©sum√© des performances, incluant les m√©triques d'√©valuation et les hyperparam√®tres utilis√©s.\n",
    "6.  **Sauvegarde du mod√®le :**\n",
    "    *   Sauvegarde le mod√®le entra√Æn√© dans un fichier pour une utilisation ult√©rieure.\n",
    "7.  **Gestion des erreurs :**\n",
    "    *   G√®re les exceptions potentielles qui peuvent survenir pendant l'ex√©cution du pipeline, affiche un message d'erreur et enregistre la trace de la pile.\n",
    "8.  **Retour des r√©sultats :**\n",
    "    *   Retourne un dictionnaire contenant les r√©sultats de l'entra√Ænement et de l'√©valuation, ou `None` en cas d'erreur.\n",
    "9.  **Notification de succ√®s :**\n",
    "    *   √âmet un bip sonore pour indiquer la fin de l'ex√©cution (si possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b0ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_path=\"UNSW_NB15_training-set.csv\", test_size=0.2, val_size=0.15, n_epochs=25, random_state=42):\n",
    "    \"\"\"\n",
    "    Fonction principale qui ex√©cute tout le pipeline MLP\n",
    "    EXACTEMENT comme dans pasteCode.ipynb\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Pipeline d'analyse et d'entra√Ænement MLP pour la d√©tection d'intrusion r√©seau\")\n",
    "    print(\"Bas√© sur la m√©thode exacte de pasteCode.ipynb avec entra√Ænement progressif\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Charger et pr√©traiter les donn√©es\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, scaler, label_encoders = load_and_preprocess_data(\n",
    "            filepath=data_path, test_size=test_size, val_size=val_size, random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Sauvegarder le scaler et les encodeurs (compatibilit√© avec le syst√®me)\n",
    "        try:\n",
    "            joblib.dump(scaler, \"models/scaler.pkl\")\n",
    "            joblib.dump(label_encoders, \"models/label_encoders.pkl\")\n",
    "            print(\"‚úÖ Scaler et encodeurs sauvegard√©s dans le dossier 'models/'\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Erreur lors de la sauvegarde du scaler et des encodeurs: {str(e)}\")\n",
    "        \n",
    "        # Utiliser les meilleurs hyperparam√®tres trouv√©s dans le notebook\n",
    "        print(\"\\nüîß Configuration des hyperparam√®tres:\")\n",
    "        \n",
    "        # Ces sont les hyperparam√®tres optimaux trouv√©s dans votre notebook\n",
    "        best_params = {\n",
    "            'activation': 'relu', \n",
    "            'alpha': 0.0001, \n",
    "            'hidden_layer_sizes': (128, 64), \n",
    "            'learning_rate': 'constant', \n",
    "            'solver': 'adam'\n",
    "        }\n",
    "        print(f\"Utilisation des hyperparam√®tres optimaux: {best_params}\")\n",
    "        \n",
    "        # Si vous voulez re-optimiser, d√©commentez ces lignes:\n",
    "        # print(\"Optimisation des hyperparam√®tres...\")\n",
    "        # best_params, val_score = optimize_mlp_hyperparameters(X_train, y_train, X_val, y_val)\n",
    "        \n",
    "        # Entra√Ænement progressif (LA M√âTHODE PR√âF√âR√âE DU NOTEBOOK)\n",
    "        print(f\"\\nü§ñ Entra√Ænement progressif du MLP (m√©thode du notebook):\")\n",
    "        results = train_mlp_progressive(X_train, y_train, X_val, y_val, X_test, y_test, best_params, n_epochs=n_epochs)\n",
    "        \n",
    "        # Affichage du temps total d'ex√©cution\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"\\nTemps total d'ex√©cution: {elapsed_time:.2f} secondes ({elapsed_time/60:.2f} minutes)\")\n",
    "        \n",
    "        # R√©sum√© des performances\n",
    "        print(f\"\\nüìä R√©sum√© des performances:\")\n",
    "        print(f\"  - Accuracy finale sur le test: {results['test_accuracy']:.4f}\")\n",
    "        print(f\"  - Precision finale sur le test: {results['test_precision']:.4f}\")\n",
    "        print(f\"  - Recall final sur le test: {results['test_recall']:.4f}\")\n",
    "        print(f\"  - F1-Score final sur le test: {results['test_f1']:.4f}\")\n",
    "        print(f\"  - Meilleure accuracy de validation: {results['best_val_accuracy']:.4f}\")\n",
    "        print(f\"  - Hyperparam√®tres utilis√©s: {best_params}\")\n",
    "        \n",
    "        # Information sur la compatibilit√©\n",
    "        print(f\"\\nüéØ SUCC√àS - Mod√®le MLP compatible cr√©√©!\")\n",
    "        print(f\"‚úÖ Sauvegard√© dans: models/mlp_best.pkl\")\n",
    "        print(f\"‚úÖ Features: {X_train.shape[1]} (compatible avec le syst√®me)\")\n",
    "        print(f\"‚úÖ M√©thode: Entra√Ænement progressif (comme dans pasteCode.ipynb)\")\n",
    "        print(f\"‚úÖ Visualisations: G√©n√©r√©es dans figures/mlp/\")\n",
    "        \n",
    "        # √âmettre un bip de succ√®s\n",
    "        try:\n",
    "            winsound.Beep(1000, 500)  # Bip de succ√®s\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Erreur lors de l'ex√©cution du pipeline: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7217d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Point d'entr√©e du script\n",
    "    print(\"üöÄ D√©marrage du re-entra√Ænement MLP avec la m√©thode du notebook\")\n",
    "    \n",
    "    # V√©rifier si le fichier de donn√©es existe\n",
    "    data_path = \"UNSW_NB15_training-set.csv\"\n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"‚ö†Ô∏è Le fichier {data_path} n'existe pas. Veuillez sp√©cifier le chemin correct.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Ex√©cuter le pipeline principal avec la m√©thode du notebook\n",
    "    results = main(data_path=data_path, n_epochs=25)\n",
    "    \n",
    "    if results:\n",
    "        print(\"\\nüéâ SUCCESS! Re-entra√Ænement MLP termin√© avec la m√©thode du notebook!\")\n",
    "        print(\"üîÑ Le mod√®le MLP est maintenant compatible et pr√™t √† √™tre utilis√© dans votre syst√®me.\")\n",
    "        print(\"üìù Remplacez l'ancien models/mlp_best.pkl - le nouveau est compatible avec 42 features.\")\n",
    "    else:\n",
    "        print(\"\\nüòû Le re-entra√Ænement a √©chou√©. V√©rifiez les erreurs ci-dessus.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
