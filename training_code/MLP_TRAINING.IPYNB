{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd3e524e",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Entraînement du modèle MLP avec la méthode exacte du notebook pasteCode.ipynb\n",
    "Utilise l'entraînement progressif préféré par l'utilisateur\n",
    "Produit un modèle compatible avec le système (42 features, nom correct)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899bf23a",
   "metadata": {},
   "source": [
    "```markdown\n",
    "Ce bloc de code importe les bibliothèques nécessaires pour l'analyse de données, la visualisation, le machine learning et la gestion des fichiers. Il configure également la gestion des avertissements et crée des répertoires pour stocker les résultats et les modèles.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61a02f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import time\n",
    "import winsound\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, log_loss, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from training_code.utils import load_and_preprocess_data,plot_training_metrics\n",
    "\n",
    "# Supprimer les avertissements non nécessaires\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "# Création des dossiers pour les résultats\n",
    "os.makedirs('figures/mlp', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb1238d",
   "metadata": {},
   "source": [
    "Ce bloc de code définit une fonction nommée `optimize_mlp_hyperparameters` qui optimise les hyperparamètres d'un modèle de réseau de neurones perceptron multicouche (MLP) à l'aide d'une recherche aléatoire avec validation croisée. Voici les étapes clés réalisées par cette fonction :\n",
    "\n",
    "1.  **Définition de l'espace de recherche des hyperparamètres :**\n",
    "    *   Définit une grille de recherche (`param_dist`) contenant différents hyperparamètres à optimiser, tels que le nombre de neurones dans les couches cachées (`hidden_layer_sizes`), la fonction d'activation (`activation`), le solveur d'optimisation (`solver`), le taux d'apprentissage (`learning_rate`) et le terme de régularisation L2 (`alpha`).\n",
    "2.  **Initialisation du modèle MLP :**\n",
    "    *   Crée une instance du modèle `MLPClassifier` avec des paramètres par défaut, tels que le nombre maximal d'itérations (`max_iter`), l'arrêt précoce (`early_stopping`) et une graine aléatoire (`random_state`).\n",
    "3.  **Recherche aléatoire avec validation croisée :**\n",
    "    *   Utilise `RandomizedSearchCV` pour effectuer une recherche aléatoire des meilleurs hyperparamètres en utilisant la validation croisée.\n",
    "    *   Évalue les performances du modèle avec différentes combinaisons d'hyperparamètres en utilisant la métrique de score spécifiée (précision).\n",
    "4.  **Entraînement et évaluation du modèle :**\n",
    "    *   Entraîne le modèle sur les données d'entraînement avec les meilleurs hyperparamètres trouvés.\n",
    "    *   Calcule le score de précision sur l'ensemble de validation.\n",
    "5.  **Affichage des résultats :**\n",
    "    *   Affiche les meilleurs hyperparamètres trouvés, le score de validation croisée et le score sur l'ensemble de validation.\n",
    "6.  **Retour des résultats :**\n",
    "    *   Retourne les meilleurs hyperparamètres et le score de validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04c4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def optimize_mlp_hyperparameters(X_train, y_train, X_val, y_val, cv=3):\n",
    "    \"\"\"\n",
    "    Optimise les hyperparamètres du modèle MLP\n",
    "    EXACTEMENT comme dans pasteCode.ipynb\n",
    "    \"\"\"\n",
    "    print(f\"Optimisation des hyperparamètres MLP...\")\n",
    "    \n",
    "    param_dist = {\n",
    "        'hidden_layer_sizes': [(64,), (128,), (64, 32), (128, 64)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'solver': ['adam', 'sgd'],\n",
    "        'alpha': [0.0001, 0.001],\n",
    "        'learning_rate': ['constant', 'adaptive']\n",
    "    }\n",
    "\n",
    "    mlp = MLPClassifier(max_iter=200, early_stopping=True, random_state=42)\n",
    "    grid_search = RandomizedSearchCV(\n",
    "        mlp, param_distributions=param_dist, n_iter=15, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    search_time = time.time() - start_time\n",
    "    print(f\"Recherche par grille terminée en {search_time:.2f} secondes\")\n",
    "\n",
    "    val_score = accuracy_score(y_val, grid_search.predict(X_val))\n",
    "    print(f\"Meilleurs hyperparamètres: {grid_search.best_params_}\")\n",
    "    print(f\"Score de validation croisée: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Score sur l'ensemble de validation: {val_score:.4f}\")\n",
    "\n",
    "    return grid_search.best_params_, val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb447f",
   "metadata": {},
   "source": [
    "Ce bloc de code définit une fonction nommée `train_mlp_progressive` qui entraîne un modèle de réseau de neurones perceptron multicouche (MLP) de manière progressive. L'entraînement progressif signifie que la taille de l'ensemble d'entraînement augmente à chaque époque. Voici les étapes clés réalisées par cette fonction :\n",
    "\n",
    "1.  **Initialisation :**\n",
    "    *   Convertit les ensembles de données en tableaux NumPy pour faciliter l'indexation.\n",
    "    *   Vérifie si les ensembles d'entraînement sont vides ou s'ils contiennent moins de deux classes, ce qui entraînerait une erreur.\n",
    "    *   Initialise des listes pour stocker les métriques d'entraînement et de validation (précision, perte, score F1 et rappel) pour chaque époque.\n",
    "    *   Initialise le modèle MLP avec les meilleurs hyperparamètres trouvés lors de l'optimisation.\n",
    "    *   Définit les valeurs de début et de fin pour l'augmentation progressive de la taille de l'ensemble d'entraînement.\n",
    "    *   Crée un dictionnaire pour stocker les indices de chaque classe dans l'ensemble d'entraînement, afin d'assurer une répartition équilibrée des classes lors de l'échantillonnage.\n",
    "2.  **Entraînement progressif :**\n",
    "    *   Itère sur le nombre d'époques spécifié.\n",
    "    *   À chaque époque, calcule la taille de l'ensemble d'entraînement en fonction de la progression linéaire définie par les valeurs de début et de fin.\n",
    "    *   Échantillonne aléatoirement les données d'entraînement en assurant une répartition équilibrée des classes.\n",
    "    *   Entraîne le modèle sur les données d'entraînement échantillonnées.\n",
    "    *   Évalue les performances du modèle sur les ensembles d'entraînement et de validation en calculant la précision, la perte, le score F1 et le rappel.\n",
    "    *   Stocke les métriques dans les listes correspondantes.\n",
    "    *   Suit le meilleur modèle en fonction de la précision sur l'ensemble de validation.\n",
    "3.  **Gestion des erreurs :**\n",
    "    *   Gère les erreurs potentielles lors de l'entraînement et de l'évaluation du modèle.\n",
    "    *   Si aucune donnée valide n'est trouvée pendant l'entraînement, un modèle par défaut est créé et entraîné.\n",
    "4.  **Visualisation des résultats :**\n",
    "    *   Trace les métriques d'entraînement et de validation en utilisant la fonction `plot_training_metrics`.\n",
    "    *   Trace la progression de la taille de l'ensemble d'entraînement au fil des époques.\n",
    "    *   Trace la matrice de confusion pour le meilleur modèle sur l'ensemble de test.\n",
    "5.  **Évaluation finale :**\n",
    "    *   Évalue les performances du meilleur modèle sur l'ensemble de test en calculant la précision, le score F1 et le rappel.\n",
    "    *   Affiche les résultats finaux.\n",
    "6.  **Sauvegarde du modèle :**\n",
    "    *   Sauvegarde le meilleur modèle dans un fichier.\n",
    "7.  **Retour des résultats :**\n",
    "    *   Retourne un dictionnaire contenant les informations d'apprentissage, les métriques et le meilleur modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaf1ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_mlp_progressive(X_train, y_train, X_val, y_val, X_test, y_test, best_params, n_epochs=25):\n",
    "    \"\"\"\n",
    "    Entraîne le modèle MLP de manière progressive en augmentant la taille de l'ensemble d'entraînement\n",
    "    EXACTEMENT comme dans pasteCode.ipynb avec l'entraînement progressif préféré\n",
    "    \"\"\"\n",
    "    print(f\"Entraînement progressif du MLP sur {n_epochs} époques...\")\n",
    "\n",
    "    # Convertir en tableaux NumPy pour éviter les problèmes d'indexation\n",
    "    if not isinstance(X_train, np.ndarray):\n",
    "        X_train = np.array(X_train)\n",
    "    if not isinstance(y_train, np.ndarray):\n",
    "        y_train = np.array(y_train)\n",
    "    if not isinstance(X_val, np.ndarray):\n",
    "        X_val = np.array(X_val)\n",
    "    if not isinstance(y_val, np.ndarray):\n",
    "        y_val = np.array(y_val)\n",
    "    if not isinstance(X_test, np.ndarray):\n",
    "        X_test = np.array(X_test)\n",
    "    if not isinstance(y_test, np.ndarray):\n",
    "        y_test = np.array(y_test)\n",
    "\n",
    "    # Vérifier si l'entraînement est possible\n",
    "    if len(X_train) == 0 or len(y_train) == 0:\n",
    "        raise ValueError(\"Ensembles d'entraînement vides\")\n",
    "    if len(np.unique(y_train)) < 2:\n",
    "        raise ValueError(\"L'ensemble d'entraînement doit contenir au moins deux classes différentes\")\n",
    "\n",
    "    # Métriques (EXACTEMENT comme dans le notebook)\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    train_precisions = []\n",
    "    val_precisions = []\n",
    "    train_recalls = []\n",
    "    val_recalls = []\n",
    "    train_f1s = []\n",
    "    val_f1s = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    epoch_train_sizes = []\n",
    "\n",
    "    # Initialiser le modèle avec les meilleurs paramètres\n",
    "    model = MLPClassifier(**best_params, random_state=42)\n",
    "\n",
    "    # Meilleur modèle\n",
    "    best_model = None\n",
    "    best_val_acc = 0\n",
    "\n",
    "    # Valeurs pour l'augmentation progressive de la taille de l'ensemble d'entraînement\n",
    "    train_ratio_start = 0.2  # Commence avec 20% des données\n",
    "    train_ratio_end = 1.0    # Termine avec 100% des données\n",
    "\n",
    "    # Assurer une répartition équilibrée des classes lors de l'échantillonnage\n",
    "    class_indices = {}\n",
    "    unique_classes = np.unique(y_train)\n",
    "    for cls in unique_classes:\n",
    "        class_indices[cls] = np.where(y_train == cls)[0]\n",
    "\n",
    "    with tqdm(total=n_epochs, desc=\"Entraînement MLP\") as pbar:\n",
    "        for epoch in range(n_epochs):\n",
    "            try:\n",
    "                # Augmentation progressive de la taille de l'entraînement\n",
    "                train_ratio = train_ratio_start + (train_ratio_end - train_ratio_start) * (epoch / max(1, n_epochs-1))\n",
    "                indices = []\n",
    "                for cls in unique_classes:\n",
    "                    n_samples = int(len(class_indices[cls]) * train_ratio)\n",
    "                    if n_samples > 0:\n",
    "                        cls_sample = np.random.choice(class_indices[cls], n_samples, replace=False)\n",
    "                        indices.extend(cls_sample)\n",
    "                np.random.shuffle(indices)\n",
    "                train_size = len(indices)\n",
    "                epoch_train_sizes.append(train_size)\n",
    "                \n",
    "                # Extraire les données d'entraînement pour cette époque\n",
    "                X_epoch = X_train[indices]\n",
    "                y_epoch = y_train[indices]\n",
    "\n",
    "                # Créer et entraîner le modèle avec les meilleurs hyperparamètres\n",
    "                model.fit(X_epoch, y_epoch)\n",
    "\n",
    "                # Évaluations\n",
    "                train_pred = model.predict(X_epoch)\n",
    "                val_pred = model.predict(X_val)\n",
    "\n",
    "                train_acc = accuracy_score(y_epoch, train_pred)\n",
    "                val_acc = accuracy_score(y_val, val_pred)\n",
    "                train_prec = precision_score(y_epoch, train_pred, zero_division=0)\n",
    "                val_prec = precision_score(y_val, val_pred, zero_division=0)\n",
    "                train_rec = recall_score(y_epoch, train_pred, zero_division=0)\n",
    "                val_rec = recall_score(y_val, val_pred, zero_division=0)\n",
    "                train_f1 = f1_score(y_epoch, train_pred, zero_division=0)\n",
    "                val_f1 = f1_score(y_val, val_pred, zero_division=0)\n",
    "\n",
    "                train_accuracies.append(train_acc)\n",
    "                val_accuracies.append(val_acc)\n",
    "                train_precisions.append(train_prec)\n",
    "                val_precisions.append(val_prec)\n",
    "                train_recalls.append(train_rec)\n",
    "                val_recalls.append(val_rec)\n",
    "                train_f1s.append(train_f1)\n",
    "                val_f1s.append(val_f1)\n",
    "\n",
    "                # Calcul des pertes (log loss) si predict_proba est disponible\n",
    "                if hasattr(model, 'predict_proba'):\n",
    "                    try:\n",
    "                        train_probs = model.predict_proba(X_epoch)\n",
    "                        val_probs = model.predict_proba(X_val)\n",
    "                        # Vérifier la validité des probabilités\n",
    "                        if not np.any(np.isnan(train_probs)) and not np.any(np.isnan(val_probs)):\n",
    "                            train_loss = log_loss(y_epoch, train_probs)\n",
    "                            val_loss = log_loss(y_val, val_probs)\n",
    "                        else:\n",
    "                            train_loss = -np.log(max(0.001, train_acc))\n",
    "                            val_loss = -np.log(max(0.001, val_acc))\n",
    "                    except Exception:\n",
    "                        # En cas d'erreur, utiliser une approximation\n",
    "                        train_loss = -np.log(max(0.001, train_acc))\n",
    "                        val_loss = -np.log(max(0.001, val_acc))\n",
    "                else:\n",
    "                    # Si predict_proba n'est pas disponible, simuler une relation inverse avec l'accuracy\n",
    "                    train_loss = -np.log(max(0.001, train_acc))\n",
    "                    val_loss = -np.log(max(0.001, val_acc))\n",
    "\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\n",
    "                    'Train Acc': f'{train_acc:.4f}',\n",
    "                    'Val Acc': f'{val_acc:.4f}',\n",
    "                    'Train Size': train_size\n",
    "                })\n",
    "\n",
    "                # Suivre le meilleur modèle\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    best_model = model\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\nErreur à l'époque {epoch+1}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    # Si aucun modèle valide n'a été trouvé, utiliser un modèle par défaut\n",
    "    if best_model is None:\n",
    "        print(\"Aucun modèle valide trouvé pendant l'entraînement. Création d'un modèle par défaut.\")\n",
    "        best_model = MLPClassifier(**best_params, random_state=42)\n",
    "        best_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Tracer les métriques d'entraînement (EXACTEMENT comme dans le notebook)\n",
    "    try:\n",
    "        plot_training_metrics(train_accuracies, val_accuracies, train_losses, val_losses, \n",
    "                             train_f1s, val_f1s, train_recalls, val_recalls, n_epochs,\n",
    "                             algorithm_name=\"MLP\", output_dir=\"figures/mlp\")\n",
    "        \n",
    "        # Graphique de la taille de l'ensemble d'entraînement\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(range(1, n_epochs+1), epoch_train_sizes, '-o', linewidth=2, markersize=4, color='#2ca02c')\n",
    "        plt.title('Progression de la taille de l\\'ensemble d\\'entraînement', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Époque', fontsize=12)\n",
    "        plt.ylabel('Nombre d\\'échantillons', fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('figures/mlp/mlp_training_size.png', dpi=300)\n",
    "        plt.close()\n",
    "        print(\"✅ Graphique de progression de taille sauvegardé\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la création des graphiques: {str(e)}\")\n",
    "\n",
    "    # Évaluation finale du meilleur modèle sur l'ensemble de test\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    test_precision = precision_score(y_test, test_pred, zero_division=0)\n",
    "    test_recall = recall_score(y_test, test_pred, zero_division=0)\n",
    "    test_f1 = f1_score(y_test, test_pred, zero_division=0)\n",
    "    conf_matrix = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "    # Tracer la matrice de confusion pour le meilleur modèle\n",
    "    try:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=['Normal', 'Attack'], yticklabels=['Normal', 'Attack'])\n",
    "        plt.title('Matrice de confusion MLP (Ensemble de test)', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Classe prédite', fontsize=12)\n",
    "        plt.ylabel('Classe réelle', fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('figures/mlp/mlp_confusion_matrix.png', dpi=300)\n",
    "        plt.close()\n",
    "        print(\"✅ Matrice de confusion sauvegardée\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la création de la matrice de confusion: {str(e)}\")\n",
    "\n",
    "    # **CRITIQUE**: Sauvegarder avec le nom attendu par le système\n",
    "    try:\n",
    "        joblib.dump(best_model, \"models/mlp_best.pkl\")\n",
    "        print(\"✅ Meilleur modèle MLP sauvegardé dans models/mlp_best.pkl\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors de la sauvegarde du modèle: {str(e)}\")\n",
    "\n",
    "    # Afficher les résultats finaux\n",
    "    print(\"\\n=== Résultats finaux ===\")\n",
    "    print(f\"Accuracy sur l'ensemble de test: {test_accuracy:.4f}\")\n",
    "    print(f\"Precision sur l'ensemble de test: {test_precision:.4f}\")\n",
    "    print(f\"Recall sur l'ensemble de test: {test_recall:.4f}\")\n",
    "    print(f\"F1-Score sur l'ensemble de test: {test_f1:.4f}\")\n",
    "    \n",
    "    # Analyser la matrice de confusion\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    total = tn + fp + fn + tp\n",
    "    print(f\"\\nDétail de la matrice de confusion:\")\n",
    "    print(f\"  - Vrais Négatifs (TN): {tn} ({tn/total*100:.2f}%)\")\n",
    "    print(f\"  - Faux Positifs (FP): {fp} ({fp/total*100:.2f}%)\")\n",
    "    print(f\"  - Faux Négatifs (FN): {fn} ({fn/total*100:.2f}%)\")\n",
    "    print(f\"  - Vrais Positifs (TP): {tp} ({tp/total*100:.2f}%)\")\n",
    "    print(f\"  - Taux de faux positifs: {fp/(fp+tn)*100:.2f}%\")\n",
    "    print(f\"  - Taux de faux négatifs: {fn/(fn+tp)*100:.2f}%\")\n",
    "\n",
    "    # Retourner les informations d'apprentissage et le meilleur modèle\n",
    "    return {\n",
    "        'model': best_model,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_precisions': train_precisions,\n",
    "        'val_precisions': val_precisions,\n",
    "        'train_recalls': train_recalls,\n",
    "        'val_recalls': val_recalls,\n",
    "        'train_f1s': train_f1s,\n",
    "        'val_f1s': val_f1s,\n",
    "        'epoch_train_sizes': epoch_train_sizes,\n",
    "        'best_val_accuracy': best_val_acc,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'test_f1': test_f1,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65877e24",
   "metadata": {},
   "source": [
    "Ce bloc de code définit la fonction principale `main` qui orchestre l'ensemble du pipeline d'entraînement et d'évaluation d'un modèle MLP (Multi-Layer Perceptron) pour la détection d'intrusion réseau. Voici les étapes clés réalisées par cette fonction :\n",
    "\n",
    "1.  **Initialisation :**\n",
    "    *   Définit les paramètres par défaut pour le chemin du fichier de données, la taille des ensembles de test et de validation, le nombre d'époques et l'état aléatoire.\n",
    "    *   Affiche un message de bienvenue décrivant le pipeline.\n",
    "    *   Enregistre le temps de début pour calculer la durée totale d'exécution.\n",
    "2.  **Chargement et prétraitement des données :**\n",
    "    *   Utilise la fonction `load_and_preprocess_data` pour charger, prétraiter et diviser les données en ensembles d'entraînement, de validation et de test.\n",
    "    *   Sauvegarde le scaler et les encodeurs de labels pour une utilisation ultérieure.\n",
    "3.  **Optimisation des hyperparamètres :**\n",
    "    *   Utilise les meilleurs hyperparamètres prédéfinis ou permet de lancer une optimisation des hyperparamètres en utilisant la fonction `optimize_mlp_hyperparameters` (cette partie est commentée par défaut).\n",
    "4.  **Entraînement du modèle :**\n",
    "    *   Entraîne le modèle MLP en utilisant la fonction `train_mlp_progressive` avec les meilleurs hyperparamètres et les ensembles de données prétraités.\n",
    "5.  **Évaluation du modèle :**\n",
    "    *   Évalue les performances du modèle entraîné sur l'ensemble de test en calculant la précision, le rappel, le score F1 et la matrice de confusion.\n",
    "    *   Affiche un résumé des performances, incluant les métriques d'évaluation et les hyperparamètres utilisés.\n",
    "6.  **Sauvegarde du modèle :**\n",
    "    *   Sauvegarde le modèle entraîné dans un fichier pour une utilisation ultérieure.\n",
    "7.  **Gestion des erreurs :**\n",
    "    *   Gère les exceptions potentielles qui peuvent survenir pendant l'exécution du pipeline, affiche un message d'erreur et enregistre la trace de la pile.\n",
    "8.  **Retour des résultats :**\n",
    "    *   Retourne un dictionnaire contenant les résultats de l'entraînement et de l'évaluation, ou `None` en cas d'erreur.\n",
    "9.  **Notification de succès :**\n",
    "    *   Émet un bip sonore pour indiquer la fin de l'exécution (si possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b0ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_path=\"UNSW_NB15_training-set.csv\", test_size=0.2, val_size=0.15, n_epochs=25, random_state=42):\n",
    "    \"\"\"\n",
    "    Fonction principale qui exécute tout le pipeline MLP\n",
    "    EXACTEMENT comme dans pasteCode.ipynb\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Pipeline d'analyse et d'entraînement MLP pour la détection d'intrusion réseau\")\n",
    "    print(\"Basé sur la méthode exacte de pasteCode.ipynb avec entraînement progressif\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Charger et prétraiter les données\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, scaler, label_encoders = load_and_preprocess_data(\n",
    "            filepath=data_path, test_size=test_size, val_size=val_size, random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Sauvegarder le scaler et les encodeurs (compatibilité avec le système)\n",
    "        try:\n",
    "            joblib.dump(scaler, \"models/scaler.pkl\")\n",
    "            joblib.dump(label_encoders, \"models/label_encoders.pkl\")\n",
    "            print(\"✅ Scaler et encodeurs sauvegardés dans le dossier 'models/'\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Erreur lors de la sauvegarde du scaler et des encodeurs: {str(e)}\")\n",
    "        \n",
    "        # Utiliser les meilleurs hyperparamètres trouvés dans le notebook\n",
    "        print(\"\\n🔧 Configuration des hyperparamètres:\")\n",
    "        \n",
    "        # Ces sont les hyperparamètres optimaux trouvés dans votre notebook\n",
    "        best_params = {\n",
    "            'activation': 'relu', \n",
    "            'alpha': 0.0001, \n",
    "            'hidden_layer_sizes': (128, 64), \n",
    "            'learning_rate': 'constant', \n",
    "            'solver': 'adam'\n",
    "        }\n",
    "        print(f\"Utilisation des hyperparamètres optimaux: {best_params}\")\n",
    "        \n",
    "        # Si vous voulez re-optimiser, décommentez ces lignes:\n",
    "        # print(\"Optimisation des hyperparamètres...\")\n",
    "        # best_params, val_score = optimize_mlp_hyperparameters(X_train, y_train, X_val, y_val)\n",
    "        \n",
    "        # Entraînement progressif (LA MÉTHODE PRÉFÉRÉE DU NOTEBOOK)\n",
    "        print(f\"\\n🤖 Entraînement progressif du MLP (méthode du notebook):\")\n",
    "        results = train_mlp_progressive(X_train, y_train, X_val, y_val, X_test, y_test, best_params, n_epochs=n_epochs)\n",
    "        \n",
    "        # Affichage du temps total d'exécution\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"\\nTemps total d'exécution: {elapsed_time:.2f} secondes ({elapsed_time/60:.2f} minutes)\")\n",
    "        \n",
    "        # Résumé des performances\n",
    "        print(f\"\\n📊 Résumé des performances:\")\n",
    "        print(f\"  - Accuracy finale sur le test: {results['test_accuracy']:.4f}\")\n",
    "        print(f\"  - Precision finale sur le test: {results['test_precision']:.4f}\")\n",
    "        print(f\"  - Recall final sur le test: {results['test_recall']:.4f}\")\n",
    "        print(f\"  - F1-Score final sur le test: {results['test_f1']:.4f}\")\n",
    "        print(f\"  - Meilleure accuracy de validation: {results['best_val_accuracy']:.4f}\")\n",
    "        print(f\"  - Hyperparamètres utilisés: {best_params}\")\n",
    "        \n",
    "        # Information sur la compatibilité\n",
    "        print(f\"\\n🎯 SUCCÈS - Modèle MLP compatible créé!\")\n",
    "        print(f\"✅ Sauvegardé dans: models/mlp_best.pkl\")\n",
    "        print(f\"✅ Features: {X_train.shape[1]} (compatible avec le système)\")\n",
    "        print(f\"✅ Méthode: Entraînement progressif (comme dans pasteCode.ipynb)\")\n",
    "        print(f\"✅ Visualisations: Générées dans figures/mlp/\")\n",
    "        \n",
    "        # Émettre un bip de succès\n",
    "        try:\n",
    "            winsound.Beep(1000, 500)  # Bip de succès\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Erreur lors de l'exécution du pipeline: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7217d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Point d'entrée du script\n",
    "    print(\"🚀 Démarrage du re-entraînement MLP avec la méthode du notebook\")\n",
    "    \n",
    "    # Vérifier si le fichier de données existe\n",
    "    data_path = \"UNSW_NB15_training-set.csv\"\n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"⚠️ Le fichier {data_path} n'existe pas. Veuillez spécifier le chemin correct.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Exécuter le pipeline principal avec la méthode du notebook\n",
    "    results = main(data_path=data_path, n_epochs=25)\n",
    "    \n",
    "    if results:\n",
    "        print(\"\\n🎉 SUCCESS! Re-entraînement MLP terminé avec la méthode du notebook!\")\n",
    "        print(\"🔄 Le modèle MLP est maintenant compatible et prêt à être utilisé dans votre système.\")\n",
    "        print(\"📝 Remplacez l'ancien models/mlp_best.pkl - le nouveau est compatible avec 42 features.\")\n",
    "    else:\n",
    "        print(\"\\n😞 Le re-entraînement a échoué. Vérifiez les erreurs ci-dessus.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
