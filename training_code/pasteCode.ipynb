{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873c2af0",
   "metadata": {},
   "source": [
    "# Network Intrusion Detection System using AI\n",
    "\n",
    "Ce notebook construit un système de détection d'intrusion réseau à double couche :\n",
    "- **Détection par signature** (Random Forest, SVM, k-NN, MLP)\n",
    "- **Détection d'anomalies** (Isolation Forest)\n",
    "\n",
    "Le dataset utilisé est UNSW-NB15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f12d67",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99b6b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import time\n",
    "import winsound\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, learning_curve, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, log_loss, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Supprimer les avertissements non nécessaires\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "# Création des dossiers pour les résultats\n",
    "os.makedirs('figures/knn_improved', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Configure logging for the classifier class\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Création des dossiers pour les résultats\n",
    "os.makedirs('figures/mlp', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101ed92f",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ead0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"UNSW_NB15_training-set.csv\")\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset preview:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "print(\"\\nClass distribution (label):\")\n",
    "print(df['label'].value_counts())\n",
    "print(\"\\nAttack categories (attack_cat):\")\n",
    "print(df['attack_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f09248",
   "metadata": {},
   "source": [
    "## 3. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f1698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution and attack categories\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "df['label'].value_counts().plot(kind='pie', autopct='%1.1f%%', ax=ax1)\n",
    "ax1.set_title('Traffic Distribution (Label)')\n",
    "ax1.set_ylabel('')\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "attack_data = df[df['label'] == 1]['attack_cat'].value_counts()\n",
    "attack_data.plot(kind='bar', ax=ax2)\n",
    "ax2.set_title('Attack Categories Distribution')\n",
    "ax2.set_ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap of numeric features (excluding 'id')\n",
    "plt.figure(figsize=(16, 12))\n",
    "numeric_cols = df.select_dtypes(include=np.number).columns.drop('id', errors='ignore')\n",
    "corr = df[numeric_cols].corr()\n",
    "sns.heatmap(corr, cmap='coolwarm', annot=False, linewidths=0.5)\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20d6243",
   "metadata": {},
   "source": [
    "## Entraînement KNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b13b18e",
   "metadata": {},
   "source": [
    "### Explication de la Fonction `load_and_preprocess_data`\n",
    "\n",
    "La fonction `load_and_preprocess_data` est conçue pour charger les données à partir d'un fichier CSV, les prétraiter et les diviser en ensembles d'entraînement, de validation et de test. Voici une explication détaillée de chaque étape :\n",
    "\n",
    "1.  **Chargement des données :**\n",
    "    *   La fonction prend en entrée le chemin du fichier CSV (`filepath`).\n",
    "    *   Elle utilise `pd.read_csv` pour charger les données dans un DataFrame pandas.\n",
    "    *   Des vérifications sont effectuées pour s'assurer que le fichier existe et que les colonnes obligatoires (`label`) sont présentes.\n",
    "\n",
    "2.  **Suppression des colonnes non nécessaires :**\n",
    "    *   Les colonnes `id` et `attack_cat` sont supprimées car elles ne sont pas nécessaires pour la classification binaire (Attaque/Normal).\n",
    "\n",
    "3.  **Gestion des valeurs manquantes :**\n",
    "    *   La fonction vérifie s'il y a des valeurs manquantes dans le DataFrame.\n",
    "    *   Si des valeurs manquantes sont détectées, les lignes correspondantes sont supprimées.\n",
    "\n",
    "4.  **Séparation des caractéristiques et des étiquettes :**\n",
    "    *   La colonne `label` est séparée du reste des données pour créer les ensembles de caractéristiques (X) et d'étiquettes (y).\n",
    "\n",
    "5.  **Encodage des caractéristiques catégorielles :**\n",
    "    *   Les colonnes catégorielles (de type `object` ou `category`) sont encodées en utilisant `LabelEncoder`.\n",
    "    *   Un `LabelEncoder` est créé pour chaque colonne catégorielle et stocké dans un dictionnaire (`label_encoders`) pour une utilisation ultérieure.\n",
    "\n",
    "6.  **Mise à l'échelle des caractéristiques numériques :**\n",
    "    *   Les caractéristiques numériques sont mises à l'échelle en utilisant `StandardScaler` pour avoir une moyenne de 0 et un écart type de 1.\n",
    "    *   Le `StandardScaler` est stocké pour une utilisation ultérieure.\n",
    "\n",
    "7.  **Division en ensembles d'entraînement, de validation et de test :**\n",
    "    *   Les données sont divisées en ensembles d'entraînement (70%), de validation (15%) et de test (15%) en utilisant `train_test_split`.\n",
    "    *   La stratification est utilisée pour s'assurer que la distribution des classes est la même dans chaque ensemble.\n",
    "\n",
    "8.  **Retour des données prétraitées :**\n",
    "    *   La fonction retourne les ensembles d'entraînement, de validation et de test, ainsi que le `StandardScaler` et les `LabelEncoder` utilisés pour le prétraitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59793ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_preprocess_data(filepath, test_size=0.2, val_size=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Charge et prétraite les données pour l'entraînement\n",
    "    Args:\n",
    "        filepath: Chemin du fichier CSV\n",
    "        test_size: Proportion de l'ensemble de test\n",
    "        val_size: Proportion de l'ensemble de validation\n",
    "        random_state: Graine aléatoire pour la reproductibilité\n",
    "    Returns:\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, scaler, label_encoders\n",
    "    \"\"\"\n",
    "    print(f\"Chargement et prétraitement des données depuis {filepath}...\")\n",
    "    \n",
    "    # Vérifier l'existence du fichier\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"Le fichier {filepath} n'existe pas.\")\n",
    "    \n",
    "    # Charger les données avec gestion d'erreurs\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Erreur lors du chargement du fichier CSV: {str(e)}\")\n",
    "    \n",
    "    print(f\"Données chargées: {df.shape[0]} lignes et {df.shape[1]} colonnes\")\n",
    "    \n",
    "    # Vérifier que les colonnes obligatoires sont présentes\n",
    "    required_cols = ['label']\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        raise ValueError(f\"Colonnes requises manquantes. Assurez-vous que {required_cols} sont présentes.\")\n",
    "    \n",
    "    # Supprimer les colonnes non nécessaires\n",
    "    df_processed = df.drop(columns=['id', 'attack_cat'], errors='ignore')\n",
    "    \n",
    "    # Afficher les informations sur les valeurs manquantes\n",
    "    missing_values = df_processed.isnull().sum()\n",
    "    missing_cols = missing_values[missing_values > 0]\n",
    "    if not missing_cols.empty:\n",
    "        print(f\"Valeurs manquantes détectées dans les colonnes suivantes:\")\n",
    "        for col, count in missing_cols.items():\n",
    "            print(f\"  - {col}: {count} valeurs manquantes ({(count/len(df_processed))*100:.2f}%)\")\n",
    "    \n",
    "    # Gérer les valeurs manquantes - considérer l'imputation plutôt que la suppression\n",
    "    rows_before = df_processed.shape[0]\n",
    "    df_processed = df_processed.dropna()\n",
    "    rows_after = df_processed.shape[0]\n",
    "    if rows_before > rows_after:\n",
    "        print(f\"Suppression de {rows_before - rows_after} lignes avec des valeurs manquantes ({(rows_before - rows_after) / rows_before * 100:.2f}%)\")\n",
    "    \n",
    "    # Séparer les caractéristiques et les étiquettes\n",
    "    X = df_processed.drop(columns=['label'], errors='ignore')\n",
    "    y = df_processed['label']  # 0 pour normal, 1 pour attaque\n",
    "    \n",
    "    # Vérifier la distribution des classes\n",
    "    class_counts = y.value_counts()\n",
    "    print(f\"Distribution des classes:\")\n",
    "    for cls, count in class_counts.items():\n",
    "        print(f\"  - Classe {cls}: {count} échantillons ({count/len(y)*100:.2f}%)\")\n",
    "    \n",
    "    # Encoder les caractéristiques catégorielles\n",
    "    label_encoders = {}\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "    if len(categorical_cols) > 0:\n",
    "        print(f\"Encodage des {len(categorical_cols)} colonnes catégorielles:\")\n",
    "        for col in categorical_cols:\n",
    "            unique_values = X[col].nunique()\n",
    "            print(f\"  - {col}: {unique_values} valeurs uniques\")\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col].astype(str))  # Convertir en string pour éviter les erreurs\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # Mise à l'échelle des caractéristiques numériques\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Division en ensembles d'entraînement, validation et test avec stratification\n",
    "    try:\n",
    "        # D'abord, séparer les données de test\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "            X_scaled, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Ensuite, diviser les données restantes en ensembles d'entraînement et de validation\n",
    "        val_ratio = val_size / (1 - test_size)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_temp, y_temp, test_size=val_ratio, random_state=random_state, stratify=y_temp\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        # Si la stratification échoue (par exemple, trop peu d'échantillons dans une classe)\n",
    "        print(f\"Avertissement lors de la stratification: {str(e)}\")\n",
    "        print(\"Tentative de division sans stratification...\")\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "            X_scaled, y, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_temp, y_temp, test_size=val_ratio, random_state=random_state\n",
    "        )\n",
    "    \n",
    "    print(f\"Dimensions des ensembles de données:\")\n",
    "    print(f\"  Train: X={X_train.shape}, y={y_train.shape}\")\n",
    "    print(f\"  Validation: X={X_val.shape}, y={y_val.shape}\")\n",
    "    print(f\"  Test: X={X_test.shape}, y={y_test.shape}\")\n",
    "    \n",
    "    # Vérifier les distributions des classes dans chaque ensemble\n",
    "    print(f\"Distribution des classes dans les ensembles:\")\n",
    "    print(f\"  Train: {np.bincount(y_train.astype(int))}\")\n",
    "    print(f\"  Validation: {np.bincount(y_val.astype(int))}\")\n",
    "    print(f\"  Test: {np.bincount(y_test.astype(int))}\")\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, scaler, label_encoders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4e6540",
   "metadata": {},
   "source": [
    "### Explication de la Fonction `optimize_knn_hyperparameters`\n",
    "\n",
    "La fonction `optimize_knn_hyperparameters` est conçue pour optimiser les hyperparamètres d'un modèle KNN (K-Nearest Neighbors) en utilisant une recherche aléatoire sur une grille de paramètres prédéfinie. Voici une explication détaillée de chaque étape :\n",
    "\n",
    "1.  **Définition de la grille de paramètres :**\n",
    "    *   Un dictionnaire `param_grid` est défini, contenant les hyperparamètres à optimiser et les valeurs possibles pour chacun d'eux.\n",
    "        *   `n_neighbors`: Nombre de voisins à considérer (3, 5, 7, 9, 11, 15).\n",
    "        *   `weights`: Pondération des voisins (uniforme ou basée sur la distance).\n",
    "        *   `metric`: Métrique de distance à utiliser (euclidienne ou de Manhattan).\n",
    "        *   `algorithm`: Algorithme utilisé pour calculer les plus proches voisins ('auto', 'ball_tree', 'kd_tree').\n",
    "\n",
    "2.  **Création du modèle KNN :**\n",
    "    *   Un modèle KNN est créé en utilisant la classe `KNeighborsClassifier` de scikit-learn.\n",
    "\n",
    "3.  **Recherche par grille avec validation croisée :**\n",
    "    *   La fonction utilise `RandomizedSearchCV` pour trouver les meilleurs hyperparamètres.\n",
    "        *   `knn`: Le modèle KNN à optimiser.\n",
    "        *   `param_grid`: La grille de paramètres à explorer.\n",
    "        *   `cv`: Le nombre de plis pour la validation croisée (par défaut 3).\n",
    "        *   `scoring`: La métrique à utiliser pour évaluer les performances (accuracy).\n",
    "        *   `n_jobs`: Le nombre de cœurs de CPU à utiliser en parallèle (-1 pour utiliser tous les cœurs disponibles).\n",
    "        *   `verbose`: Niveau de verbosité (1 pour afficher des informations pendant la recherche).\n",
    "\n",
    "4.  **Entraînement du modèle :**\n",
    "    *   La fonction entraîne le modèle en utilisant la méthode `fit` de `RandomizedSearchCV`.\n",
    "    *   Le temps d'entraînement est mesuré pour évaluer l'efficacité de la recherche.\n",
    "\n",
    "5.  **Évaluation sur l'ensemble de validation :**\n",
    "    *   Une fois la recherche terminée, le modèle est évalué sur l'ensemble de validation en utilisant la méthode `predict` pour obtenir les prédictions, puis en calculant l'accuracy avec `accuracy_score`.\n",
    "\n",
    "6.  **Affichage des résultats :**\n",
    "    *   Les meilleurs hyperparamètres trouvés sont affichés, ainsi que le score de validation croisée et le score sur l'ensemble de validation.\n",
    "    *   Les 3 meilleures combinaisons de paramètres sont également affichées, avec leurs scores moyens et écarts-types.\n",
    "\n",
    "7.  **Gestion des erreurs :**\n",
    "    *   Si une erreur se produit pendant l'optimisation, la fonction utilise des paramètres par défaut pour créer et entraîner un modèle KNN.\n",
    "\n",
    "8.  **Retour des résultats :**\n",
    "    *   La fonction retourne les meilleurs hyperparamètres trouvés et le score de validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d4221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimize_knn_hyperparameters(X_train, y_train, X_val, y_val, cv=3):\n",
    "    \"\"\"\n",
    "    Optimise les hyperparamètres du modèle KNN\n",
    "    Args:\n",
    "        X_train: Caractéristiques d'entraînement\n",
    "        y_train: Étiquettes d'entraînement\n",
    "        X_val: Caractéristiques de validation\n",
    "        y_val: Étiquettes de validation\n",
    "        cv: Nombre de plis pour la validation croisée\n",
    "    Returns:\n",
    "        Meilleurs hyperparamètres et score\n",
    "    \"\"\"\n",
    "    print(f\"Optimisation des hyperparamètres KNN...\")\n",
    "    \n",
    "    # Définir une grille de paramètres plus efficace\n",
    "    param_grid = {\n",
    "        'n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree']\n",
    "    }\n",
    "    \n",
    "    # Créer le modèle KNN\n",
    "    knn = KNeighborsClassifier()\n",
    "    \n",
    "    # Utiliser GridSearchCV pour trouver les meilleurs hyperparamètres\n",
    "    print(f\"Lancement de la recherche par grille avec {cv} plis...\")\n",
    "    grid_search = RandomizedSearchCV(\n",
    "        knn, param_grid, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Entraîner le modèle avec gestion du temps\n",
    "        start_time = time.time()\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        search_time = time.time() - start_time\n",
    "        print(f\"Recherche par grille terminée en {search_time:.2f} secondes\")\n",
    "        \n",
    "        # Évaluer sur l'ensemble de validation\n",
    "        val_score = accuracy_score(y_val, grid_search.predict(X_val))\n",
    "        print(f\"Meilleurs hyperparamètres: {grid_search.best_params_}\")\n",
    "        print(f\"Score de validation croisée: {grid_search.best_score_:.4f}\")\n",
    "        print(f\"Score sur l'ensemble de validation: {val_score:.4f}\")\n",
    "        \n",
    "        # Afficher les 3 meilleures combinaisons de paramètres\n",
    "        results = grid_search.cv_results_\n",
    "        sorted_idx = np.argsort(results['mean_test_score'])[::-1]\n",
    "        print(\"\\nTop 3 des meilleures combinaisons de paramètres:\")\n",
    "        for i in range(min(3, len(sorted_idx))):\n",
    "            idx = sorted_idx[i]\n",
    "            print(f\"Rang {i+1}: {results['params'][idx]}\")\n",
    "            print(f\"  Score moyen: {results['mean_test_score'][idx]:.4f}\")\n",
    "            print(f\"  Écart-type: {results['std_test_score'][idx]:.4f}\")\n",
    "        \n",
    "        return grid_search.best_params_, val_score\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'optimisation des hyperparamètres: {str(e)}\")\n",
    "        # Paramètres par défaut en cas d'erreur\n",
    "        default_params = {'n_neighbors': 5, 'weights': 'uniform', 'metric': 'euclidean', 'algorithm': 'auto'}\n",
    "        print(f\"Utilisation des paramètres par défaut: {default_params}\")\n",
    "        model = KNeighborsClassifier(**default_params)\n",
    "        model.fit(X_train, y_train)\n",
    "        val_score = accuracy_score(y_val, model.predict(X_val))\n",
    "        return default_params, val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3140ce32",
   "metadata": {},
   "source": [
    "### Explication de la Fonction `plot_learning_curve`\n",
    "\n",
    "La fonction `plot_learning_curve` est conçue pour évaluer l'impact de la taille de l'ensemble d'entraînement sur les performances du modèle KNN. Elle utilise la fonction `learning_curve` de scikit-learn pour générer des courbes d'apprentissage qui montrent comment l'accuracy du modèle évolue en fonction de la taille de l'ensemble d'entraînement. Voici une explication détaillée de chaque étape :\n",
    "\n",
    "1.  **Préparation du graphique :**\n",
    "    *   La fonction prend en entrée un estimateur (le modèle KNN), les caractéristiques (X), les étiquettes (y), le nombre de plis pour la validation croisée (cv), le nombre de jobs pour le calcul parallèle (n\\_jobs) et les tailles relatives de l'ensemble d'entraînement à évaluer (train\\_sizes).\n",
    "    *   Elle crée une figure matplotlib pour afficher les courbes d'apprentissage.\n",
    "\n",
    "2.  **Génération des courbes d'apprentissage :**\n",
    "    *   La fonction utilise la fonction `learning_curve` de scikit-learn pour générer les courbes d'apprentissage.\n",
    "        *   `estimator`: Le modèle à évaluer.\n",
    "        *   `X`: Les caractéristiques.\n",
    "        *   `y`: Les étiquettes.\n",
    "        *   `train_sizes`: Les tailles relatives de l'ensemble d'entraînement à évaluer.\n",
    "        *   `cv`: Le nombre de plis pour la validation croisée.\n",
    "        *   `n_jobs`: Le nombre de jobs pour le calcul parallèle.\n",
    "        *   `scoring`: La métrique à utiliser pour évaluer les performances (accuracy).\n",
    "        *   `shuffle`: Mélanger les données avant de les diviser en plis.\n",
    "        *   `random_state`: Graine aléatoire pour la reproductibilité.\n",
    "    *   La fonction `learning_curve` retourne les tailles de l'ensemble d'entraînement, les scores d'entraînement et les scores de validation.\n",
    "\n",
    "3.  **Calcul des moyennes et écarts-types :**\n",
    "    *   La fonction calcule les moyennes et les écarts-types des scores d'entraînement et de validation pour chaque taille d'ensemble d'entraînement.\n",
    "\n",
    "4.  **Traçage des courbes d'apprentissage :**\n",
    "    *   La fonction trace les courbes d'apprentissage en utilisant les moyennes et les écarts-types calculés.\n",
    "    *   Elle utilise des couleurs et des styles différents pour les courbes d'entraînement et de validation.\n",
    "    *   Elle ajoute une zone ombrée autour de chaque courbe pour représenter l'écart-type.\n",
    "\n",
    "5.  **Amélioration de l'aspect du graphique :**\n",
    "    *   La fonction ajoute un titre, des étiquettes d'axe, une grille et une légende au graphique.\n",
    "    *   Elle utilise des polices de caractères plus grandes et plus grasses pour améliorer la lisibilité.\n",
    "    *   Elle ajuste la disposition du graphique pour éviter les chevauchements.\n",
    "\n",
    "6.  **Ajout d'informations importantes :**\n",
    "    *   La fonction ajoute une annotation pour indiquer la taille de l'ensemble d'entraînement qui donne la meilleure accuracy de validation.\n",
    "\n",
    "7.  **Sauvegarde du graphique :**\n",
    "    *   La fonction sauvegarde le graphique dans un fichier PNG.\n",
    "\n",
    "8.  **Gestion des erreurs :**\n",
    "    *   Si une erreur se produit pendant le traçage des courbes d'apprentissage, la fonction affiche un message d'erreur et ferme la figure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d06545",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_learning_curve(estimator, X, y, cv=5, n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10)):\n",
    "    \"\"\"\n",
    "    Trace la courbe d'apprentissage pour évaluer l'impact de la taille de l'ensemble d'entraînement\n",
    "    Args:\n",
    "        estimator: Le modèle à évaluer\n",
    "        X: Caractéristiques\n",
    "        y: Étiquettes\n",
    "        cv: Nombre de plis pour la validation croisée\n",
    "        n_jobs: Nombre de jobs pour le calcul parallèle\n",
    "        train_sizes: Tailles relatives de l'ensemble d'entraînement à évaluer\n",
    "    \"\"\"\n",
    "    print(\"Traçage de la courbe d'apprentissage...\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    try:\n",
    "        train_sizes, train_scores, val_scores = learning_curve(\n",
    "            estimator, X, y, train_sizes=train_sizes, cv=cv, n_jobs=n_jobs,\n",
    "            scoring='accuracy', shuffle=True, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Calculer les moyennes et écarts-types\n",
    "        train_mean = np.mean(train_scores, axis=1)\n",
    "        train_std = np.std(train_scores, axis=1)\n",
    "        val_mean = np.mean(val_scores, axis=1)\n",
    "        val_std = np.std(val_scores, axis=1)\n",
    "        \n",
    "        # Tracer les courbes d'apprentissage avec un style amélioré\n",
    "        plt.plot(train_sizes, train_mean, 'o-', color='#1f77b4', label='Entraînement', linewidth=2)\n",
    "        plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2, color='#1f77b4')\n",
    "        plt.plot(train_sizes, val_mean, 'o-', color='#ff7f0e', label='Validation', linewidth=2)\n",
    "        plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.2, color='#ff7f0e')\n",
    "        \n",
    "        # Améliorer l'aspect du graphique\n",
    "        plt.title('Courbe d\\'apprentissage KNN', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Taille de l\\'ensemble d\\'entraînement', fontsize=12)\n",
    "        plt.ylabel('Accuracy', fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.legend(loc='lower right', fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Ajouter des informations importantes\n",
    "        max_val_mean = np.max(val_mean)\n",
    "        max_val_idx = np.argmax(val_mean)\n",
    "        max_val_size = train_sizes[max_val_idx]\n",
    "        plt.annotate(f'Maximum: {max_val_mean:.4f}',\n",
    "                    xy=(max_val_size, max_val_mean),\n",
    "                    xytext=(max_val_size, max_val_mean - 0.1),\n",
    "                    arrowprops=dict(facecolor='black', shrink=0.05, width=1.5),\n",
    "                    fontsize=10, ha='center')\n",
    "        \n",
    "        plt.savefig('figures/knn_improved/knn_learning_curve.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"✅ Courbe d'apprentissage enregistrée dans figures/knn_improved/knn_learning_curve.png\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du traçage de la courbe d'apprentissage: {str(e)}\")\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da48e4b8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Explication de la Fonction `plot_training_metrics`\n",
    "\n",
    "La fonction `plot_training_metrics` est conçue pour visualiser les métriques d'entraînement et de validation au fil des époques lors de l'entraînement d'un modèle KNN. Elle prend en entrée les listes des accuracies, losses, F1-scores et recalls pour les ensembles d'entraînement et de validation, ainsi que le nombre total d'époques. Voici une explication détaillée de chaque étape :\n",
    "\n",
    "1.  **Configuration de la figure :**\n",
    "    *   La fonction crée une figure avec quatre sous-graphiques disposés en une grille 2x2. Chaque sous-graphique affichera une métrique différente (accuracy, loss, F1-score, recall).\n",
    "    *   La taille de la figure est définie pour une meilleure lisibilité.\n",
    "\n",
    "2.  **Style commun pour les graphiques :**\n",
    "    *   Une boucle est utilisée pour appliquer un style commun à tous les sous-graphiques :\n",
    "        *   Ajout d'une grille en arrière-plan pour faciliter la lecture des valeurs.\n",
    "        *   Placement de la grille derrière les données pour ne pas obstruer les courbes.\n",
    "\n",
    "3.  **Traçage des métriques :**\n",
    "    *   Pour chaque métrique (accuracy, loss, F1-score, recall) :\n",
    "        *   Les valeurs d'entraînement et de validation sont tracées en fonction du nombre d'époques.\n",
    "        *   Des couleurs et des étiquettes différentes sont utilisées pour distinguer les courbes d'entraînement et de validation.\n",
    "        *   Un titre est ajouté pour identifier la métrique affichée.\n",
    "        *   Des étiquettes sont ajoutées pour les axes x et y.\n",
    "        *   Une légende est ajoutée pour identifier les courbes.\n",
    "\n",
    "4.  **Amélioration de la lisibilité :**\n",
    "    *   La fonction utilise des polices de caractères plus grandes et plus grasses pour améliorer la lisibilité des titres et des étiquettes.\n",
    "    *   Elle ajuste la disposition des sous-graphiques pour éviter les chevauchements.\n",
    "\n",
    "5.  **Sauvegarde de la figure :**\n",
    "    *   La figure est sauvegardée dans un fichier PNG.\n",
    "\n",
    "6.  **Retour de la figure :**\n",
    "    *   La fonction retourne la figure matplotlib créée, ce qui permet de la manipuler ou de la fermer ultérieurement si nécessaire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c07657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_metrics(\n",
    "     train_accuracies, val_accuracies, train_losses, val_losses,\n",
    "     train_f1s, val_f1s, train_recalls, val_recalls, n_epochs,\n",
    "     algorithm_name=\"XGBoost\", output_dir=\"figures/xgb\"):\n",
    "     \"\"\"\n",
    "     Fonction dédiée pour tracer les métriques d'entraînement et enregistrer chaque graphe dans un fichier séparé.\n",
    "     Args:\n",
    "          train_accuracies: Liste des accuracies d'entraînement\n",
    "          val_accuracies: Liste des accuracies de validation\n",
    "          train_losses: Liste des pertes d'entraînement\n",
    "          val_losses: Liste des pertes de validation\n",
    "          train_f1s: Liste des F1 scores d'entraînement\n",
    "          val_f1s: Liste des F1 scores de validation\n",
    "          train_recalls: Liste des recalls d'entraînement\n",
    "          val_recalls: Liste des recalls de validation\n",
    "          n_epochs: Nombre d'époques\n",
    "          algorithm_name: Nom de l'algorithme pour les titres (défaut: \"XGBoost\")\n",
    "          output_dir: Répertoire de sortie pour les figures (défaut: \"figures/xgb\")\n",
    "     Returns:\n",
    "          None\n",
    "     \"\"\"\n",
    "     # Style commun pour tous les graphiques\n",
    "     metrics = {\n",
    "          'Accuracy': (train_accuracies, val_accuracies),\n",
    "          'Loss': (train_losses, val_losses),\n",
    "          'F1 Score': (train_f1s, val_f1s),\n",
    "          'Recall': (train_recalls, val_recalls)\n",
    "     }\n",
    "\n",
    "     for metric_name, (train_metric, val_metric) in metrics.items():\n",
    "          fig, ax = plt.subplots(figsize=(10, 6))\n",
    "          ax.grid(True, linestyle='--', alpha=0.7)\n",
    "          ax.set_axisbelow(True)  # Placer la grille derrière les données\n",
    "\n",
    "          # Graphique de la métrique\n",
    "          ax.plot(range(1, n_epochs + 1), train_metric, '-o', label='Entraînement', color='#1f77b4',\n",
    "                    linewidth=2, markersize=5, alpha=0.8)\n",
    "          ax.plot(range(1, n_epochs + 1), val_metric, '-o', label='Validation', color='#ff7f0e',\n",
    "                    linewidth=2, markersize=5, alpha=0.8)\n",
    "          ax.set_title(f'{algorithm_name} - {metric_name}', fontsize=16, fontweight='bold')\n",
    "          ax.set_xlabel('Époque', fontsize=14)\n",
    "          ax.set_ylabel(metric_name, fontsize=14)\n",
    "          ax.legend(fontsize=12)\n",
    "\n",
    "          # Ajouter des annotations pour les valeurs maximales (validation)\n",
    "          max_val_metric = max(val_metric)\n",
    "          max_val_metric_idx = val_metric.index(max_val_metric)\n",
    "          ax.annotate(f'Max: {max_val_metric:.4f}',\n",
    "                         xy=(max_val_metric_idx + 1, max_val_metric),\n",
    "                         xytext=(max_val_metric_idx + 1, max_val_metric - 0.05),\n",
    "                         arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "                         fontsize=12, ha='center')\n",
    "\n",
    "          plt.tight_layout()\n",
    "\n",
    "          # Assurer que le répertoire de sortie existe\n",
    "          os.makedirs(output_dir, exist_ok=True)\n",
    "          output_path = os.path.join(output_dir, f'{algorithm_name.lower()}_{metric_name.lower().replace(\" \", \"_\")}.png')\n",
    "          plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "          print(f\"✅ Métriques d'entraînement enregistrées dans {output_path}\")\n",
    "          plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bbbef2",
   "metadata": {},
   "source": [
    "### Explication de la Fonction `train_knn_progressive`\n",
    "\n",
    "La fonction `train_knn_progressive` est conçue pour entraîner un modèle KNN de manière progressive, en augmentant graduellement la taille de l'ensemble d'entraînement à chaque époque. Cette approche permet d'observer l'évolution des performances du modèle en fonction de la quantité de données utilisées pour l'entraînement. Voici une explication détaillée de chaque étape :\n",
    "\n",
    "1.  **Initialisation :**\n",
    "    *   La fonction prend en entrée les ensembles d'entraînement (X\\_train, y\\_train), de validation (X\\_val, y\\_val) et de test (X\\_test, y\\_test), les meilleurs hyperparamètres trouvés lors de l'optimisation (best\\_params) et le nombre d'époques d'entraînement (n\\_epochs).\n",
    "    *   Elle initialise des listes pour stocker les métriques d'entraînement et de validation à chaque époque (accuracy, loss, precision, recall, f1-score).\n",
    "    *   Elle initialise également des variables pour suivre le meilleur modèle (celui qui obtient la meilleure accuracy sur l'ensemble de validation).\n",
    "\n",
    "2.  **Boucle d'entraînement :**\n",
    "    *   La fonction effectue une boucle sur le nombre d'époques spécifié.\n",
    "    *   À chaque époque, elle augmente progressivement la taille de l'ensemble d'entraînement en utilisant un ratio qui varie de train\\_ratio\\_start à train\\_ratio\\_end.\n",
    "    *   Elle sélectionne un sous-ensemble aléatoire de l'ensemble d'entraînement en utilisant ce ratio.\n",
    "    *   Elle crée un modèle KNN avec les meilleurs hyperparamètres trouvés et l'entraîne sur le sous-ensemble sélectionné.\n",
    "    *   Elle évalue les performances du modèle sur les ensembles d'entraînement et de validation en calculant l'accuracy, la loss, la precision, le recall et le f1-score.\n",
    "    *   Elle met à jour le meilleur modèle si les performances sur l'ensemble de validation sont meilleures que celles du meilleur modèle précédent.\n",
    "\n",
    "3.  **Évaluation finale :**\n",
    "    *   Une fois la boucle d'entraînement terminée, la fonction évalue les performances du meilleur modèle sur l'ensemble de test en calculant l'accuracy, la precision, le recall et le f1-score.\n",
    "    *   Elle calcule également la matrice de confusion pour analyser les erreurs de classification du modèle.\n",
    "\n",
    "4.  **Traçage des courbes d'apprentissage :**\n",
    "    *   La fonction trace les courbes d'apprentissage pour visualiser l'évolution des métriques d'entraînement et de validation au fil des époques.\n",
    "    *   Elle trace également la matrice de confusion pour visualiser les performances du modèle sur l'ensemble de test.\n",
    "\n",
    "5.  **Retour des résultats :**\n",
    "    *   La fonction retourne un dictionnaire contenant les informations d'apprentissage (métriques d'entraînement et de validation, courbes d'apprentissage) et le meilleur modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d6f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_knn_progressive(X_train, y_train, X_val, y_val, X_test, y_test, best_params, n_epochs=50):\n",
    "    \"\"\"\n",
    "    Entraîne le modèle KNN de manière progressive en augmentant la taille de l'ensemble d'entraînement\n",
    "    Args:\n",
    "        X_train: Caractéristiques d'entraînement\n",
    "        y_train: Étiquettes d'entraînement\n",
    "        X_val: Caractéristiques de validation\n",
    "        y_val: Étiquettes de validation\n",
    "        X_test: Caractéristiques de test\n",
    "        y_test: Étiquettes de test\n",
    "        best_params: Meilleurs hyperparamètres trouvés\n",
    "        n_epochs: Nombre d'époques d'entraînement\n",
    "    Returns:\n",
    "        Historique des métriques et meilleur modèle\n",
    "    \"\"\"\n",
    "    print(f\"Entraînement progressif du KNN sur {n_epochs} époques...\")\n",
    "    \n",
    "    # Convertir en tableaux NumPy pour éviter les problèmes d'indexation\n",
    "    if not isinstance(X_train, np.ndarray):\n",
    "        X_train = np.array(X_train)\n",
    "    if not isinstance(y_train, np.ndarray):\n",
    "        y_train = np.array(y_train)\n",
    "        \n",
    "    # Vérifier si l'entraînement est possible\n",
    "    if len(X_train) == 0 or len(y_train) == 0:\n",
    "        raise ValueError(\"Ensembles d'entraînement vides\")\n",
    "    \n",
    "    if len(np.unique(y_train)) < 2:\n",
    "        raise ValueError(\"L'ensemble d'entraînement doit contenir au moins deux classes différentes\")\n",
    "    \n",
    "    # Listes pour stocker les métriques\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    train_precisions = []\n",
    "    val_precisions = []\n",
    "    train_recalls = []\n",
    "    val_recalls = []\n",
    "    train_f1s = []\n",
    "    val_f1s = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    epoch_train_sizes = []\n",
    "    \n",
    "    # Meilleur modèle\n",
    "    best_model = None\n",
    "    best_val_acc = 0\n",
    "    \n",
    "    # Valeurs pour l'augmentation progressive de la taille de l'ensemble d'entraînement\n",
    "    train_ratio_start = 0.2  # Commence avec 20% des données\n",
    "    train_ratio_end = 1.0    # Termine avec 100% des données\n",
    "    \n",
    "    # Assurer une répartition équilibrée des classes lors de l'échantillonnage\n",
    "    class_indices = {}\n",
    "    unique_classes = np.unique(y_train)\n",
    "    for cls in unique_classes:\n",
    "        class_indices[cls] = np.where(y_train == cls)[0]\n",
    "    \n",
    "    # Barre de progression\n",
    "    with tqdm(total=n_epochs, desc=\"Entraînement\") as pbar:\n",
    "        for epoch in range(n_epochs):\n",
    "            try:\n",
    "                # Augmentation progressive de la taille de l'entraînement\n",
    "                train_ratio = train_ratio_start + (train_ratio_end - train_ratio_start) * (epoch / max(1, n_epochs-1))\n",
    "                \n",
    "                # Sélectionner un échantillon stratifié\n",
    "                indices = []\n",
    "                for cls in unique_classes:\n",
    "                    cls_indices = class_indices[cls]\n",
    "                    # Calculer le nombre d'échantillons à prendre pour cette classe\n",
    "                    n_samples = int(len(cls_indices) * train_ratio)\n",
    "                    if n_samples > 0:\n",
    "                        # Prendre un échantillon aléatoire de cette classe\n",
    "                        cls_sample_indices = np.random.choice(cls_indices, n_samples, replace=False)\n",
    "                        indices.extend(cls_sample_indices)\n",
    "                \n",
    "                # Mélanger les indices\n",
    "                np.random.shuffle(indices)\n",
    "                train_size = len(indices)\n",
    "                epoch_train_sizes.append(train_size)\n",
    "                \n",
    "                # Extraire les données d'entraînement pour cette époque\n",
    "                X_train_epoch = X_train[indices]\n",
    "                y_train_epoch = y_train[indices]\n",
    "                \n",
    "                # Créer et entraîner le modèle avec les meilleurs hyperparamètres\n",
    "                model = KNeighborsClassifier(**best_params)\n",
    "                model.fit(X_train_epoch, y_train_epoch)\n",
    "                \n",
    "                # Évaluation sur l'ensemble d'entraînement\n",
    "                train_preds = model.predict(X_train_epoch)\n",
    "                train_acc = accuracy_score(y_train_epoch, train_preds)\n",
    "                train_prec = precision_score(y_train_epoch, train_preds, zero_division=0)\n",
    "                train_rec = recall_score(y_train_epoch, train_preds, zero_division=0)\n",
    "                train_f1 = f1_score(y_train_epoch, train_preds, zero_division=0)\n",
    "                train_accuracies.append(train_acc)\n",
    "                train_precisions.append(train_prec)\n",
    "                train_recalls.append(train_rec)\n",
    "                train_f1s.append(train_f1)\n",
    "                \n",
    "                # Évaluation sur l'ensemble de validation\n",
    "                val_preds = model.predict(X_val)\n",
    "                val_acc = accuracy_score(y_val, val_preds)\n",
    "                val_prec = precision_score(y_val, val_preds, zero_division=0)\n",
    "                val_rec = recall_score(y_val, val_preds, zero_division=0)\n",
    "                val_f1 = f1_score(y_val, val_preds, zero_division=0)\n",
    "                val_accuracies.append(val_acc)\n",
    "                val_precisions.append(val_prec)\n",
    "                val_recalls.append(val_rec)\n",
    "                val_f1s.append(val_f1)\n",
    "                \n",
    "                # Calcul des pertes (log loss) si predict_proba est disponible\n",
    "                if hasattr(model, 'predict_proba'):\n",
    "                    try:\n",
    "                        train_probs = model.predict_proba(X_train_epoch)\n",
    "                        val_probs = model.predict_proba(X_val)\n",
    "                        \n",
    "                        # Vérifier la validité des probabilités\n",
    "                        if not np.any(np.isnan(train_probs)) and not np.any(np.isnan(val_probs)):\n",
    "                            train_loss = log_loss(y_train_epoch, train_probs)\n",
    "                            val_loss = log_loss(y_val, val_probs)\n",
    "                        else:\n",
    "                            train_loss = -np.log(max(0.001, train_acc))\n",
    "                            val_loss = -np.log(max(0.001, val_acc))\n",
    "                    except Exception:\n",
    "                        # En cas d'erreur, utiliser une approximation\n",
    "                        train_loss = -np.log(max(0.001, train_acc))\n",
    "                        val_loss = -np.log(max(0.001, val_acc))\n",
    "                else:\n",
    "                    # Si predict_proba n'est pas disponible, simuler une relation inverse avec l'accuracy\n",
    "                    train_loss = -np.log(max(0.001, train_acc))\n",
    "                    val_loss = -np.log(max(0.001, val_acc))\n",
    "                    \n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                \n",
    "                # Suivre le meilleur modèle\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    best_model = model\n",
    "                \n",
    "                # Mettre à jour la barre de progression\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\n",
    "                    'Train Acc': f'{train_acc:.4f}',\n",
    "                    'Val Acc': f'{val_acc:.4f}',\n",
    "                    'Train Size': train_size\n",
    "                })\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"\\nErreur à l'époque {epoch+1}: {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    # Si aucun modèle valide n'a été trouvé, utiliser un modèle par défaut\n",
    "    if best_model is None:\n",
    "        print(\"Aucun modèle valide trouvé pendant l'entraînement. Création d'un modèle par défaut.\")\n",
    "        best_model = KNeighborsClassifier(**best_params)\n",
    "        best_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Évaluation finale du meilleur modèle sur l'ensemble de test\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    test_precision = precision_score(y_test, test_pred, zero_division=0)\n",
    "    test_recall = recall_score(y_test, test_pred, zero_division=0)\n",
    "    test_f1 = f1_score(y_test, test_pred, zero_division=0)\n",
    "    \n",
    "    # Calculer la matrice de confusion\n",
    "    conf_matrix = confusion_matrix(y_test, test_pred)\n",
    "    \n",
    "    # Tracer les courbes d'apprentissage\n",
    "    try:\n",
    "        plot_training_metrics(train_accuracies, val_accuracies, train_losses, val_losses, \n",
    "                             train_f1s, val_f1s, train_recalls, val_recalls, n_epochs,\n",
    "                             algorithm_name=\"KNN\", output_dir=\"figures/knn_improved\"\n",
    "                             )\n",
    "        \n",
    "        # Graphique de la taille de l'ensemble d'entraînement\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(range(1, n_epochs+1), epoch_train_sizes, '-o', linewidth=2, markersize=4, color='#2ca02c')\n",
    "        plt.title('Progression de la taille de l\\'ensemble d\\'entraînement', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Époque', fontsize=12)\n",
    "        plt.ylabel('Nombre d\\'échantillons', fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('figures/knn_improved/knn_training_size.png', dpi=300)\n",
    "        \n",
    "        # Tracer la matrice de confusion pour le meilleur modèle\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=['Normal', 'Attack'], yticklabels=['Normal', 'Attack'])\n",
    "        plt.title('Matrice de confusion (Ensemble de test)', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Classe prédite', fontsize=12)\n",
    "        plt.ylabel('Classe réelle', fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('figures/knn_improved/knn_confusion_matrix.png', dpi=300)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la création des graphiques: {str(e)}\")\n",
    "    \n",
    "    # Afficher les résultats finaux\n",
    "    print(\"\\n=== Résultats finaux ===\")\n",
    "    print(f\"Accuracy sur l'ensemble de test: {test_accuracy:.4f}\")\n",
    "    print(f\"Precision sur l'ensemble de test: {test_precision:.4f}\")\n",
    "    print(f\"Recall sur l'ensemble de test: {test_recall:.4f}\")\n",
    "    print(f\"F1-Score sur l'ensemble de test: {test_f1:.4f}\")\n",
    "    \n",
    "    # Ajouter une fonction de classification des prédictions (par ex. pour calculer les taux de faux positifs/négatifs)\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    total = tn + fp + fn + tp\n",
    "    print(f\"\\nDétail de la matrice de confusion:\")\n",
    "    print(f\"  - Vrais Négatifs (TN): {tn} ({tn/total*100:.2f}%)\")\n",
    "    print(f\"  - Faux Positifs (FP): {fp} ({fp/total*100:.2f}%)\")\n",
    "    print(f\"  - Faux Négatifs (FN): {fn} ({fn/total*100:.2f}%)\")\n",
    "    print(f\"  - Vrais Positifs (TP): {tp} ({tp/total*100:.2f}%)\")\n",
    "    print(f\"  - Taux de faux positifs: {fp/(fp+tn)*100:.2f}%\")\n",
    "    print(f\"  - Taux de faux négatifs: {fn/(fn+tp)*100:.2f}%\")\n",
    "    \n",
    "    # Retourner les informations d'apprentissage et le meilleur modèle\n",
    "    return {\n",
    "        'model': best_model,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_precisions': train_precisions,\n",
    "        'val_precisions': val_precisions,\n",
    "        'train_recalls': train_recalls,\n",
    "        'val_recalls': val_recalls,\n",
    "        'train_f1s': train_f1s,\n",
    "        'val_f1s': val_f1s,\n",
    "        'epoch_train_sizes': epoch_train_sizes,\n",
    "        'best_val_accuracy': best_val_acc,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'test_f1': test_f1,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2696d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(data_path=\"UNSW_NB15_training-set.csv\", test_size=0.2, val_size=0.15, n_epochs=50, random_state=42):\n",
    "    \"\"\"\n",
    "    Fonction principale qui exécute tout le pipeline\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Charger et prétraiter les données\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, scaler, label_encoders = load_and_preprocess_data(\n",
    "            filepath=data_path, test_size=test_size, val_size=val_size, random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Sauvegarder le scaler et les encodeurs\n",
    "        try:\n",
    "            joblib.dump(scaler, \"models/scaler.pkl\")\n",
    "            joblib.dump(label_encoders, \"models/label_encoders.pkl\")\n",
    "            print(\"✅ Scaler et encodeurs sauvegardés dans le dossier 'models/'\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Erreur lors de la sauvegarde du scaler et des encodeurs: {str(e)}\")\n",
    "        \n",
    "        # Optimiser les hyperparamètres\n",
    "        best_params, val_score = optimize_knn_hyperparameters(X_train, y_train, X_val, y_val)\n",
    "        \n",
    "        # Tracer la courbe d'apprentissage pour évaluer l'impact de la taille de l'ensemble d'entraînement\n",
    "        model = KNeighborsClassifier(**best_params)\n",
    "        plot_learning_curve(model, X_train, y_train)\n",
    "        \n",
    "        # Entraînement progressif\n",
    "        results = train_knn_progressive(X_train, y_train, X_val, y_val, X_test, y_test, best_params, n_epochs=n_epochs)\n",
    "        \n",
    "        # Sauvegarder le meilleur modèle\n",
    "        try:\n",
    "            joblib.dump(results['model'], \"models/KNN_best.pkl\")\n",
    "            print(\"✅ Meilleur modèle KNN sauvegardé dans models/KNN_best.pkl\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Erreur lors de la sauvegarde du modèle: {str(e)}\")\n",
    "        \n",
    "        # Affichage du temps total d'exécution\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"\\nTemps total d'exécution: {elapsed_time:.2f} secondes ({elapsed_time/60:.2f} minutes)\")\n",
    "        \n",
    "        # Résumé des performances\n",
    "        print(f\"\\n📊 Résumé des performances:\")\n",
    "        print(f\"  - Accuracy finale sur le test: {results['test_accuracy']:.4f}\")\n",
    "        print(f\"  - Precision finale sur le test: {results['test_precision']:.4f}\")\n",
    "        print(f\"  - Recall final sur le test: {results['test_recall']:.4f}\")\n",
    "        print(f\"  - F1-Score final sur le test: {results['test_f1']:.4f}\")\n",
    "        print(f\"  - Meilleure accuracy de validation: {results['best_val_accuracy']:.4f}\")\n",
    "        print(f\"  - Meilleurs hyperparamètres: {best_params}\")\n",
    "        \n",
    "        # Évaluation finale du modèle\n",
    "        print(\"\\n🔍 Analyse de la matrice de confusion:\")\n",
    "        conf_matrix = results['confusion_matrix']\n",
    "        tn, fp, fn, tp = conf_matrix.ravel()\n",
    "        print(f\"  - Vrais Négatifs (Normal correctement identifié): {tn}\")\n",
    "        print(f\"  - Faux Positifs (Normal classé comme Attaque): {fp}\")\n",
    "        print(f\"  - Faux Négatifs (Attaque classée comme Normale): {fn}\")\n",
    "        print(f\"  - Vrais Positifs (Attaque correctement identifiée): {tp}\")\n",
    "        \n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        print(f\"  - Spécificité (Taux de vrais négatifs): {specificity:.4f}\")\n",
    "        \n",
    "        winsound.Beep(1000, 500)  # Bip de 1 seconde à 1000 Hz\n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Erreur lors de l'exécution du pipeline: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5507b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Point d'entrée du script\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Pipeline d'analyse et d'entraînement KNN pour la détection d'intrusion réseau\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Vérifier si le fichier de données existe\n",
    "    data_path = \"UNSW_NB15_training-set.csv\"\n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"⚠️ Le fichier {data_path} n'existe pas. Veuillez spécifier le chemin correct.\")\n",
    "        data_path = input(\"Chemin du fichier de données: \")\n",
    "    \n",
    "    # Exécuter le pipeline principal\n",
    "    main(data_path=data_path, n_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des dossiers pour les résultats\n",
    "os.makedirs('figures/mlp', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f246651c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optimize_mlp_hyperparameters(X_train, y_train, X_val, y_val, cv=3):\n",
    "    \"\"\"\n",
    "    Optimise les hyperparamètres du modèle MLP\n",
    "    Args:\n",
    "        X_train: Caractéristiques d'entraînement\n",
    "        y_train: Étiquettes d'entraînement\n",
    "        X_val: Caractéristiques de validation\n",
    "        y_val: Étiquettes de validation\n",
    "        cv: Nombre de plis pour la validation croisée\n",
    "    Returns:\n",
    "        Meilleurs hyperparamètres et score\n",
    "    \"\"\"\n",
    "    print(f\"Optimisation des hyperparamètres MLP...\")\n",
    "    param_dist = {\n",
    "        'hidden_layer_sizes': [(64,), (128,), (64, 32), (128, 64)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'solver': ['adam', 'sgd'],\n",
    "        'alpha': [0.0001, 0.001],\n",
    "        'learning_rate': ['constant', 'adaptive']\n",
    "    }\n",
    "\n",
    "    mlp = MLPClassifier(max_iter=200, early_stopping=True, random_state=42)\n",
    "    grid_search = RandomizedSearchCV(\n",
    "        mlp, param_distributions=param_dist, n_iter=15, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    search_time = time.time() - start_time\n",
    "    print(f\"Recherche par grille terminée en {search_time:.2f} secondes\")\n",
    "\n",
    "    val_score = accuracy_score(y_val, grid_search.predict(X_val))\n",
    "    print(f\"Meilleurs hyperparamètres: {grid_search.best_params_}\")\n",
    "    print(f\"Score de validation croisée: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Score sur l'ensemble de validation: {val_score:.4f}\")\n",
    "\n",
    "    return grid_search.best_params_, val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_mlp_progressive(X_train, y_train, X_val, y_val, X_test, y_test, best_params, n_epochs=25):\n",
    "    \"\"\"\n",
    "    Entraîne le modèle MLP de manière progressive en augmentant la taille de l'ensemble d'entraînement\n",
    "    Args:\n",
    "        X_train: Caractéristiques d'entraînement\n",
    "        y_train: Étiquettes d'entraînement\n",
    "        X_val: Caractéristiques de validation\n",
    "        y_val: Étiquettes de validation\n",
    "        X_test: Caractéristiques de test\n",
    "        y_test: Étiquettes de test\n",
    "        best_params: Meilleurs hyperparamètres trouvés\n",
    "        n_epochs: Nombre d'époques d'entraînement\n",
    "    Returns:\n",
    "        Historique des métriques et meilleur modèle\n",
    "    \"\"\"\n",
    "    print(f\"Entraînement progressif du MLP sur {n_epochs} époques...\")\n",
    "\n",
    "    # Convertir en tableaux NumPy pour éviter les problèmes d'indexation\n",
    "    if not isinstance(X_train, np.ndarray):\n",
    "        X_train = np.array(X_train)\n",
    "    if not isinstance(y_train, np.ndarray):\n",
    "        y_train = np.array(y_train)\n",
    "    if not isinstance(X_val, np.ndarray):\n",
    "        X_val = np.array(X_val)\n",
    "    if not isinstance(y_val, np.ndarray):\n",
    "        y_val = np.array(y_val)\n",
    "    if not isinstance(X_test, np.ndarray):\n",
    "        X_test = np.array(X_test)\n",
    "    if not isinstance(y_test, np.ndarray):\n",
    "        y_test = np.array(y_test)\n",
    "\n",
    "    # Vérifier si l'entraînement est possible\n",
    "    if len(X_train) == 0 or len(y_train) == 0:\n",
    "        raise ValueError(\"Ensembles d'entraînement vides\")\n",
    "    if len(np.unique(y_train)) < 2:\n",
    "        raise ValueError(\"L'ensemble d'entraînement doit contenir au moins deux classes différentes\")\n",
    "\n",
    "    # Métriques\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    train_precisions = []\n",
    "    val_precisions = []\n",
    "    train_recalls = []\n",
    "    val_recalls = []\n",
    "    train_f1s = []\n",
    "    val_f1s = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    epoch_train_sizes = []\n",
    "\n",
    "    # Initialiser le modèle avec les meilleurs paramètres\n",
    "    model = MLPClassifier(**best_params, random_state=42)\n",
    "\n",
    "    # Meilleur modèle\n",
    "    best_model = None\n",
    "    best_val_acc = 0\n",
    "\n",
    "    # Valeurs pour l'augmentation progressive de la taille de l'ensemble d'entraînement\n",
    "    train_ratio_start = 0.2  # Commence avec 20% des données\n",
    "    train_ratio_end = 1.0    # Termine avec 100% des données\n",
    "\n",
    "    # Assurer une répartition équilibrée des classes lors de l'échantillonnage\n",
    "    class_indices = {}\n",
    "    unique_classes = np.unique(y_train)\n",
    "    for cls in unique_classes:\n",
    "        class_indices[cls] = np.where(y_train == cls)[0]\n",
    "\n",
    "    with tqdm(total=n_epochs, desc=\"Entraînement\") as pbar:\n",
    "        for epoch in range(n_epochs):\n",
    "            try:\n",
    "                # Augmentation progressive de la taille de l'entraînement\n",
    "                train_ratio = train_ratio_start + (train_ratio_end - train_ratio_start) * (epoch / max(1, n_epochs-1))\n",
    "                indices = []\n",
    "                for cls in unique_classes:\n",
    "                    n_samples = int(len(class_indices[cls]) * train_ratio)\n",
    "                    cls_sample = np.random.choice(class_indices[cls], n_samples, replace=False)\n",
    "                    indices.extend(cls_sample)\n",
    "                np.random.shuffle(indices)\n",
    "                train_size = len(indices)\n",
    "                epoch_train_sizes.append(train_size)\n",
    "                # Extraire les données d'entraînement pour cette époque\n",
    "                X_epoch = X_train[indices]\n",
    "                y_epoch = y_train[indices]\n",
    "\n",
    "                # Créer et entraîner le modèle avec les meilleurs hyperparamètres\n",
    "                model.fit(X_epoch, y_epoch)\n",
    "\n",
    "                # Évaluations\n",
    "                train_pred = model.predict(X_epoch)\n",
    "                val_pred = model.predict(X_val)\n",
    "\n",
    "                train_accuracies.append(accuracy_score(y_epoch, train_pred))\n",
    "                val_accuracies.append(accuracy_score(y_val, val_pred))\n",
    "                train_precisions.append(precision_score(y_epoch, train_pred, zero_division=0))\n",
    "                val_precisions.append(precision_score(y_val, val_pred, zero_division=0))\n",
    "                train_recalls.append(recall_score(y_epoch, train_pred, zero_division=0))\n",
    "                val_recalls.append(recall_score(y_val, val_pred, zero_division=0))\n",
    "                train_f1s.append(f1_score(y_epoch, train_pred, zero_division=0))\n",
    "                val_f1s.append(f1_score(y_val, val_pred, zero_division=0))\n",
    "\n",
    "                # Calcul des pertes (log loss) si predict_proba est disponible\n",
    "                if hasattr(model, 'predict_proba'):\n",
    "                    try:\n",
    "                        train_probs = model.predict_proba(X_epoch)\n",
    "                        val_probs = model.predict_proba(X_val)\n",
    "                        # Vérifier la validité des probabilités\n",
    "                        if not np.any(np.isnan(train_probs)) and not np.any(np.isnan(val_probs)):\n",
    "                            train_loss = log_loss(y_epoch, train_probs)\n",
    "                            val_loss = log_loss(y_val, val_probs)\n",
    "                        else:\n",
    "                            train_loss = -np.log(max(0.001, train_accuracies[-1]))\n",
    "                            val_loss = -np.log(max(0.001, val_accuracies[-1]))\n",
    "                    except Exception:\n",
    "                        # En cas d'erreur, utiliser une approximation\n",
    "                        train_loss = -np.log(max(0.001, train_accuracies[-1]))\n",
    "                        val_loss = -np.log(max(0.001, val_accuracies[-1]))\n",
    "                else:\n",
    "                    # Si predict_proba n'est pas disponible, simuler une relation inverse avec l'accuracy\n",
    "                    train_loss = -np.log(max(0.001, train_accuracies[-1]))\n",
    "                    val_loss = -np.log(max(0.001, val_accuracies[-1]))\n",
    "\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\n",
    "                    'Train Acc': f'{train_accuracies[-1]:.4f}',\n",
    "                    'Val Acc': f'{val_accuracies[-1]:.4f}',\n",
    "                    'Train Size': train_size\n",
    "                })\n",
    "\n",
    "                # Suivre le meilleur modèle\n",
    "                if val_accuracies[-1] > best_val_acc:\n",
    "                    best_val_acc = val_accuracies[-1]\n",
    "                    best_model = model\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur à l'époque {epoch+1}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    # Si aucun modèle valide n'a été trouvé, utiliser un modèle par défaut\n",
    "    if best_model is None:\n",
    "        print(\"Aucun modèle valide trouvé pendant l'entraînement. Création d'un modèle par défaut.\")\n",
    "        best_model = MLPClassifier(**best_params, random_state=42)\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "     \n",
    "    try:\n",
    "        plot_training_metrics(train_accuracies, val_accuracies, train_losses, val_losses, \n",
    "                             train_f1s, val_f1s, train_recalls, val_recalls, n_epochs,\n",
    "                             algorithm_name=\"MLP\", output_dir=\"figures/mlp\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la création des graphiques: {str(e)}\")\n",
    "    # Évaluation finale du meilleur modèle sur l'ensemble de test\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    test_precision = precision_score(y_test, test_pred, zero_division=0)\n",
    "    test_recall = recall_score(y_test, test_pred, zero_division=0)\n",
    "    test_f1 = f1_score(y_test, test_pred, zero_division=0)\n",
    "    conf_matrix = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "\n",
    "    # Sauvegarder\n",
    "    joblib.dump(best_model, \"models/mlp_best.pkl\")\n",
    "    print(\"✅ Meilleur modèle MLP sauvegardé\")\n",
    "\n",
    "    return {\n",
    "        'model': best_model,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'test_f1': test_f1,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c357c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    data_path = \"UNSW_NB15_training-set.csv\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Pipeline d'analyse et d'entraînement MLP pour la détection d'intrusion réseau\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test, scaler, encoders = load_and_preprocess_data(data_path)\n",
    "    joblib.dump(scaler, \"models/scaler_mlp.pkl\")\n",
    "    joblib.dump(encoders, \"models/label_encoders_mlp.pkl\")\n",
    "\n",
    "    # Optimiser les hyperparamètres\n",
    "    # best_params, val_score = optimize_mlp_hyperparameters(X_train, y_train, X_val, y_val)\n",
    "    best_params={'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'constant', 'solver': 'adam'}\n",
    "    # Tracer la courbe d'apprentissage pour évaluer l'impact de la taille de l'ensemble d'entraînement\n",
    "    # model = MLPClassifier(**best_params)\n",
    "    # plot_learning_curve(model, X_train, y_train)\n",
    "    # Entraînement progressif\n",
    "    results = train_mlp_progressive(X_train, y_train, X_val, y_val, X_test, y_test, best_params, n_epochs=25)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"\\nTemps total d'exécution: {elapsed_time:.2f} secondes ({elapsed_time / 60:.2f} minutes)\")\n",
    "    print(\"\\n📊 Résumé des performances:\")\n",
    "    print(f\"Accuracy finale sur le test: {results['test_accuracy']:.4f}\")\n",
    "    print(f\"Precision finale sur le test: {results['test_precision']:.4f}\")\n",
    "    print(f\"Recall final sur le test: {results['test_recall']:.4f}\")\n",
    "    print(f\"F1-Score final sur le test: {results['test_f1']:.4f}\")\n",
    "    print(f\"Meilleurs hyperparamètres: {best_params}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cf53e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Meilleurs hyperparamètres: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128, 64), 'learning_rate': 'constant', 'solver': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e8a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, log_loss\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# Supprimer les avertissements non nécessaires\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "# Création des dossiers pour les résultats\n",
    "os.makedirs('figures/xgb', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "\n",
    "def optimize_xgb_hyperparameters(X_train, y_train, X_val, y_val, cv=3):\n",
    "    \"\"\"\n",
    "    Optimise les hyperparamètres du modèle XGBoost\n",
    "    Args:\n",
    "        X_train: Caractéristiques d'entraînement\n",
    "        y_train: Étiquettes d'entraînement\n",
    "        X_val: Caractéristiques de validation\n",
    "        y_val: Étiquettes de validation\n",
    "        cv: Nombre de plis pour la validation croisée\n",
    "    Returns:\n",
    "        Meilleurs hyperparamètres et score\n",
    "    \"\"\"\n",
    "    print(f\"Optimisation des hyperparamètres XGBoost...\")\n",
    "    param_dist = {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0],\n",
    "        'gamma': [0, 0.1, 0.2],\n",
    "        'reg_alpha': [0, 0.1, 0.2],\n",
    "        'reg_lambda': [1, 1.5, 2]\n",
    "    }\n",
    "\n",
    "    xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "    grid_search = RandomizedSearchCV(\n",
    "        xgb, param_distributions=param_dist, n_iter=15, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    search_time = time.time() - start_time\n",
    "    print(f\"Recherche par grille terminée en {search_time:.2f} secondes\")\n",
    "\n",
    "    val_score = accuracy_score(y_val, grid_search.predict(X_val))\n",
    "    print(f\"Meilleurs hyperparamètres: {grid_search.best_params_}\")\n",
    "    print(f\"Score de validation croisée: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Score sur l'ensemble de validation: {val_score:.4f}\")\n",
    "\n",
    "    return grid_search.best_params_, val_score\n",
    "\n",
    "\n",
    "def train_xgb_progressive(X_train, y_train, X_val, y_val, X_test, y_test, best_params, n_epochs=25):\n",
    "    \"\"\"\n",
    "    Entraîne le modèle XGBoost de manière progressive en augmentant la taille de l'ensemble d'entraînement\n",
    "    Args:\n",
    "        X_train: Caractéristiques d'entraînement\n",
    "        y_train: Étiquettes d'entraînement\n",
    "        X_val: Caractéristiques de validation\n",
    "        y_val: Étiquettes de validation\n",
    "        X_test: Caractéristiques de test\n",
    "        y_test: Étiquettes de test\n",
    "        best_params: Meilleurs hyperparamètres trouvés\n",
    "        n_epochs: Nombre d'époques d'entraînement\n",
    "    Returns:\n",
    "        Historique des métriques et meilleur modèle\n",
    "    \"\"\"\n",
    "    print(f\"Entraînement progressif du XGBoost sur {n_epochs} époques...\")\n",
    "\n",
    "    # Métriques\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    train_precisions = []\n",
    "    val_precisions = []\n",
    "    train_recalls = []\n",
    "    val_recalls = []\n",
    "    train_f1s = []\n",
    "    val_f1s = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    epoch_train_sizes = []\n",
    "     # Convertir en tableaux NumPy pour éviter les problèmes d'indexation\n",
    "    if not isinstance(X_train, np.ndarray):\n",
    "        X_train = np.array(X_train)\n",
    "    if not isinstance(y_train, np.ndarray):\n",
    "        y_train = np.array(y_train)\n",
    "    if not isinstance(X_val, np.ndarray):\n",
    "        X_val = np.array(X_val)\n",
    "    if not isinstance(y_val, np.ndarray):\n",
    "        y_val = np.array(y_val)\n",
    "    if not isinstance(X_test, np.ndarray):\n",
    "        X_test = np.array(X_test)\n",
    "    if not isinstance(y_test, np.ndarray):\n",
    "        y_test = np.array(y_test)\n",
    "\n",
    "    # Initialiser le modèle avec les meilleurs paramètres\n",
    "    model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "\n",
    "    # Meilleur modèle\n",
    "    best_model = None\n",
    "    best_val_acc = 0\n",
    "\n",
    "    # Valeurs pour l'augmentation progressive de la taille de l'ensemble d'entraînement\n",
    "    train_ratio_start = 0.2  # Commence avec 20% des données\n",
    "    train_ratio_end = 1.0    # Termine avec 100% des données\n",
    "\n",
    "    # Assurer une répartition équilibrée des classes lors de l'échantillonnage\n",
    "    class_indices = {}\n",
    "    unique_classes = np.unique(y_train)\n",
    "    for cls in unique_classes:\n",
    "        class_indices[cls] = np.where(y_train == cls)[0]\n",
    "\n",
    "    with tqdm(total=n_epochs, desc=\"Entraînement\") as pbar:\n",
    "        for epoch in range(n_epochs):\n",
    "            try:\n",
    "                # Augmentation progressive de la taille de l'entraînement\n",
    "                train_ratio = train_ratio_start + (train_ratio_end - train_ratio_start) * (epoch / max(1, n_epochs-1))\n",
    "                indices = []\n",
    "                for cls in unique_classes:\n",
    "                    n_samples = int(len(class_indices[cls]) * train_ratio)\n",
    "                    cls_sample = np.random.choice(class_indices[cls], n_samples, replace=False)\n",
    "                    indices.extend(cls_sample)\n",
    "                np.random.shuffle(indices)\n",
    "                train_size = len(indices)\n",
    "                epoch_train_sizes.append(train_size)\n",
    "                # Extraire les données d'entraînement pour cette époque\n",
    "                X_epoch = X_train[indices]\n",
    "                y_epoch = y_train[indices]\n",
    "\n",
    "                # Créer et entraîner le modèle avec les meilleurs hyperparamètres\n",
    "                model.fit(X_epoch, y_epoch)\n",
    "\n",
    "                # Évaluations\n",
    "                train_pred = model.predict(X_epoch)\n",
    "                val_pred = model.predict(X_val)\n",
    "\n",
    "                train_accuracies.append(accuracy_score(y_epoch, train_pred))\n",
    "                val_accuracies.append(accuracy_score(y_val, val_pred))\n",
    "                train_precisions.append(precision_score(y_epoch, train_pred, zero_division=0))\n",
    "                val_precisions.append(precision_score(y_val, val_pred, zero_division=0))\n",
    "                train_recalls.append(recall_score(y_epoch, train_pred, zero_division=0))\n",
    "                val_recalls.append(recall_score(y_val, val_pred, zero_division=0))\n",
    "                train_f1s.append(f1_score(y_epoch, train_pred, zero_division=0))\n",
    "                val_f1s.append(f1_score(y_val, val_pred, zero_division=0))\n",
    "\n",
    "                # Calcul des pertes (log loss) si predict_proba est disponible\n",
    "                if hasattr(model, 'predict_proba'):\n",
    "                    try:\n",
    "                        train_probs = model.predict_proba(X_epoch)\n",
    "                        val_probs = model.predict_proba(X_val)\n",
    "                        # Vérifier la validité des probabilités\n",
    "                        if not np.any(np.isnan(train_probs)) and not np.any(np.isnan(val_probs)):\n",
    "                            train_loss = log_loss(y_epoch, train_probs)\n",
    "                            val_loss = log_loss(y_val, val_probs)\n",
    "                        else:\n",
    "                            train_loss = -np.log(max(0.001, train_accuracies[-1]))\n",
    "                            val_loss = -np.log(max(0.001, val_accuracies[-1]))\n",
    "                    except Exception:\n",
    "                        # En cas d'erreur, utiliser une approximation\n",
    "                        train_loss = -np.log(max(0.001, train_accuracies[-1]))\n",
    "                        val_loss = -np.log(max(0.001, val_accuracies[-1]))\n",
    "                else:\n",
    "                    # Si predict_proba n'est pas disponible, simuler une relation inverse avec l'accuracy\n",
    "                    train_loss = -np.log(max(0.001, train_accuracies[-1]))\n",
    "                    val_loss = -np.log(max(0.001, val_accuracies[-1]))\n",
    "\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\n",
    "                    'Train Acc': f'{train_accuracies[-1]:.4f}',\n",
    "                    'Val Acc': f'{val_accuracies[-1]:.4f}',\n",
    "                    'Train Size': train_size\n",
    "                })\n",
    "\n",
    "                # Suivre le meilleur modèle\n",
    "                if val_accuracies[-1] > best_val_acc:\n",
    "                    best_val_acc = val_accuracies[-1]\n",
    "                    best_model = model\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur à l'époque {epoch+1}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    # Si aucun modèle valide n'a été trouvé, utiliser un modèle par défaut\n",
    "    if best_model is None:\n",
    "        print(\"Aucun modèle valide trouvé pendant l'entraînement. Création d'un modèle par défaut.\")\n",
    "        best_model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "    try:\n",
    "        plot_training_metrics(\n",
    "            train_accuracies, val_accuracies, train_losses, val_losses, \n",
    "            train_f1s, val_f1s, train_recalls, val_recalls, n_epochs,\n",
    "            algorithm_name=\"XGBoost\", output_dir=\"figures/xgb\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la création des graphiques: {str(e)}\")\n",
    "\n",
    "    # Évaluation finale du meilleur modèle sur l'ensemble de test\n",
    "    test_pred = best_model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    test_precision = precision_score(y_test, test_pred, zero_division=0)\n",
    "    test_recall = recall_score(y_test, test_pred, zero_division=0)\n",
    "    test_f1 = f1_score(y_test, test_pred, zero_division=0)\n",
    "    conf_matrix = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "    # Sauvegarder\n",
    "    joblib.dump(best_model, \"models/xgb_best.pkl\")\n",
    "    print(\"✅ Meilleur modèle XGBoost sauvegardé\")\n",
    "\n",
    "    return {\n",
    "        'model': best_model,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'test_f1': test_f1,\n",
    "        'confusion_matrix': conf_matrix\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_training_size(epoch_train_sizes, n_epochs):\n",
    "    \"\"\"\n",
    "    Trace la progression de la taille de l'ensemble d'entraînement\n",
    "    Args:\n",
    "        epoch_train_sizes: Liste des tailles d'entraînement à chaque époque\n",
    "        n_epochs: Nombre d'époques\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, n_epochs+1), epoch_train_sizes, '-o', linewidth=2, markersize=4, color='#2ca02c')\n",
    "    plt.title('Progression de la taille de l\\'ensemble d\\'entraînement', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Époque', fontsize=12)\n",
    "    plt.ylabel('Nombre d\\'échantillons', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/xgb/xgb_training_size.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix):\n",
    "    \"\"\"\n",
    "    Trace la matrice de confusion\n",
    "    Args:\n",
    "        conf_matrix: Matrice de confusion\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Normal', 'Attack'], yticklabels=['Normal', 'Attack'])\n",
    "    plt.title('Matrice de confusion (Ensemble de test)', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Classe prédite', fontsize=12)\n",
    "    plt.ylabel('Classe réelle', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/xgb/xgb_confusion_matrix.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def main(data_path=\"UNSW_NB15_training-set.csv\", test_size=0.2, val_size=0.15, n_epochs=25, random_state=42):\n",
    "    \"\"\"\n",
    "    Fonction principale qui exécute tout le pipeline\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Pipeline d'analyse et d'entraînement XGBoost pour la détection d'intrusion réseau\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test, scaler, encoders = load_and_preprocess_data(\n",
    "        filepath=data_path, test_size=test_size, val_size=val_size, random_state=random_state\n",
    "    )\n",
    "    joblib.dump(scaler, \"models/scaler_xgb.pkl\")\n",
    "    joblib.dump(encoders, \"models/label_encoders_xgb.pkl\")\n",
    "\n",
    "    # Optimiser les hyperparamètres\n",
    "    best_params, val_score = optimize_xgb_hyperparameters(X_train, y_train, X_val, y_val, cv=3)\n",
    "    # Tracer la courbe d'apprentissage pour évaluer l'impact de la taille de l'ensemble d'entraînement\n",
    "    model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "    plot_learning_curve(model, X_train, y_train)\n",
    "    # Entraînement progressif\n",
    "    results = train_xgb_progressive(X_train, y_train, X_val, y_val, X_test, y_test, best_params, n_epochs=n_epochs)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"\\nTemps total d'exécution: {elapsed_time:.2f} secondes ({elapsed_time / 60:.2f} minutes)\")\n",
    "    print(\"\\n📊 Résumé des performances:\")\n",
    "    print(f\"Accuracy finale sur le test: {results['test_accuracy']:.4f}\")\n",
    "    print(f\"Precision finale sur le test: {results['test_precision']:.4f}\")\n",
    "    print(f\"Recall final sur le test: {results['test_recall']:.4f}\")\n",
    "    print(f\"F1-Score final sur le test: {results['test_f1']:.4f}\")\n",
    "    print(f\"Meilleurs hyperparamètres: {best_params}\")\n",
    "\n",
    "    # Évaluation finale du modèle\n",
    "    print(\"🔍 Analyse de la matrice de confusion:\")\n",
    "    conf_matrix = results['confusion_matrix']\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    total = tn + fp + fn + tp\n",
    "    print(f\" - Vrais Négatifs (TN): {tn} ({tn/total*100:.2f}%)\")\n",
    "    print(f\" - Faux Positifs (FP): {fp} ({fp/total*100:.2f}%)\")\n",
    "    print(f\" - Faux Négatifs (FN): {fn} ({fn/total*100:.2f}%)\")\n",
    "    print(f\" - Vrais Positifs (TP): {tp} ({tp/total*100:.2f}%)\")\n",
    "    print(f\" - Taux de faux positifs: {fp/(fp+tn)*100:.2f}%\")\n",
    "    print(f\" - Taux de faux négatifs: {fn/(fn+tp)*100:.2f}%\")\n",
    "\n",
    "\n",
    "    # Tracer la matrice de confusion pour le meilleur modèle\n",
    "    plot_confusion_matrix(conf_matrix)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
