"""
Re-entra√Ænement du mod√®le MLP avec la m√©thode exacte du notebook pasteCode.ipynb
Utilise l'entra√Ænement progressif pr√©f√©r√© par l'utilisateur
Produit un mod√®le compatible avec le syst√®me (42 features, nom correct)
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import os
import logging
import warnings
import time
import winsound
from tqdm import tqdm

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split, learning_curve, RandomizedSearchCV
from sklearn.metrics import accuracy_score, log_loss, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.neural_network import MLPClassifier
from sklearn.exceptions import ConvergenceWarning

# Supprimer les avertissements non n√©cessaires
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=ConvergenceWarning)

# Cr√©ation des dossiers pour les r√©sultats
os.makedirs('figures/mlp', exist_ok=True)
os.makedirs('models', exist_ok=True)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def load_and_preprocess_data(filepath, test_size=0.2, val_size=0.15, random_state=42):
    """
    Charge et pr√©traite les donn√©es pour l'entra√Ænement MLP
    EXACTEMENT comme dans pasteCode.ipynb
    Assure la compatibilit√© avec 42 features (sans colonne 'id')
    """
    print(f"Chargement et pr√©traitement des donn√©es depuis {filepath}...")
    
    # V√©rifier l'existence du fichier
    if not os.path.exists(filepath):
        raise FileNotFoundError(f"Le fichier {filepath} n'existe pas.")
    
    # Charger les donn√©es avec gestion d'erreurs
    try:
        df = pd.read_csv(filepath)
    except Exception as e:
        raise Exception(f"Erreur lors du chargement du fichier CSV: {str(e)}")
    
    print(f"Donn√©es charg√©es: {df.shape[0]} lignes et {df.shape[1]} colonnes")
    
    # V√©rifier que les colonnes obligatoires sont pr√©sentes
    required_cols = ['label']
    if not all(col in df.columns for col in required_cols):
        raise ValueError(f"Colonnes requises manquantes. Assurez-vous que {required_cols} sont pr√©sentes.")
    
    # **CRITIQUE**: Supprimer les colonnes non n√©cessaires (EXACTEMENT comme dans le notebook)
    # Cela garantit 42 features au lieu de 43 (compatible avec le syst√®me)
    df_processed = df.drop(columns=['id', 'attack_cat'], errors='ignore')
    
    print(f"Colonnes apr√®s suppression de 'id' et 'attack_cat': {df_processed.shape[1]} colonnes")
    
    # Afficher les informations sur les valeurs manquantes
    missing_values = df_processed.isnull().sum()
    missing_cols = missing_values[missing_values > 0]
    if not missing_cols.empty:
        print(f"Valeurs manquantes d√©tect√©es dans les colonnes suivantes:")
        for col, count in missing_cols.items():
            print(f"  - {col}: {count} valeurs manquantes ({(count/len(df_processed))*100:.2f}%)")
    
    # G√©rer les valeurs manquantes - consid√©rer l'imputation plut√¥t que la suppression
    rows_before = df_processed.shape[0]
    df_processed = df_processed.dropna()
    rows_after = df_processed.shape[0]
    if rows_before > rows_after:
        print(f"Suppression de {rows_before - rows_after} lignes avec des valeurs manquantes ({(rows_before - rows_after) / rows_before * 100:.2f}%)")
    
    # S√©parer les caract√©ristiques et les √©tiquettes
    X = df_processed.drop(columns=['label'], errors='ignore')
    y = df_processed['label']  # 0 pour normal, 1 pour attaque
    
    print(f"Features finales: {X.shape[1]} colonnes (compatible avec le syst√®me)")
    
    # V√©rifier la distribution des classes
    class_counts = y.value_counts()
    print(f"Distribution des classes:")
    for cls, count in class_counts.items():
        print(f"  - Classe {cls}: {count} √©chantillons ({count/len(y)*100:.2f}%)")
    
    # Encoder les caract√©ristiques cat√©gorielles
    label_encoders = {}
    categorical_cols = X.select_dtypes(include=['object', 'category']).columns
    if len(categorical_cols) > 0:
        print(f"Encodage des {len(categorical_cols)} colonnes cat√©gorielles:")
        for col in categorical_cols:
            unique_values = X[col].nunique()
            print(f"  - {col}: {unique_values} valeurs uniques")
            le = LabelEncoder()
            X[col] = le.fit_transform(X[col].astype(str))  # Convertir en string pour √©viter les erreurs
            label_encoders[col] = le
    
    # Mise √† l'√©chelle des caract√©ristiques num√©riques
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    print(f"Forme finale des donn√©es apr√®s preprocessing: {X_scaled.shape}")
    
    # Division en ensembles d'entra√Ænement, validation et test avec stratification
    try:
        # D'abord, s√©parer les donn√©es de test
        X_temp, X_test, y_temp, y_test = train_test_split(
            X_scaled, y, test_size=test_size, random_state=random_state, stratify=y
        )
        
        # Ensuite, diviser les donn√©es restantes en ensembles d'entra√Ænement et de validation
        val_ratio = val_size / (1 - test_size)
        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp, test_size=val_ratio, random_state=random_state, stratify=y_temp
        )
    except ValueError as e:
        # Si la stratification √©choue (par exemple, trop peu d'√©chantillons dans une classe)
        print(f"Avertissement lors de la stratification: {str(e)}")
        print("Tentative de division sans stratification...")
        X_temp, X_test, y_temp, y_test = train_test_split(
            X_scaled, y, test_size=test_size, random_state=random_state
        )
        val_ratio = val_size / (1 - test_size)
        X_train, X_val, y_train, y_val = train_test_split(
            X_temp, y_temp, test_size=val_ratio, random_state=random_state
        )
    
    print(f"Dimensions des ensembles de donn√©es:")
    print(f"  Train: X={X_train.shape}, y={y_train.shape}")
    print(f"  Validation: X={X_val.shape}, y={y_val.shape}")
    print(f"  Test: X={X_test.shape}, y={y_test.shape}")
    
    # V√©rifier les distributions des classes dans chaque ensemble
    print(f"Distribution des classes dans les ensembles:")
    print(f"  Train: {np.bincount(y_train.astype(int))}")
    print(f"  Validation: {np.bincount(y_val.astype(int))}")
    print(f"  Test: {np.bincount(y_test.astype(int))}")
    
    return X_train, X_val, X_test, y_train, y_val, y_test, scaler, label_encoders


def optimize_mlp_hyperparameters(X_train, y_train, X_val, y_val, cv=3):
    """
    Optimise les hyperparam√®tres du mod√®le MLP
    EXACTEMENT comme dans pasteCode.ipynb
    """
    print(f"Optimisation des hyperparam√®tres MLP...")
    
    param_dist = {
        'hidden_layer_sizes': [(64,), (128,), (64, 32), (128, 64)],
        'activation': ['relu', 'tanh'],
        'solver': ['adam', 'sgd'],
        'alpha': [0.0001, 0.001],
        'learning_rate': ['constant', 'adaptive']
    }

    mlp = MLPClassifier(max_iter=200, early_stopping=True, random_state=42)
    grid_search = RandomizedSearchCV(
        mlp, param_distributions=param_dist, n_iter=15, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1
    )

    start_time = time.time()
    grid_search.fit(X_train, y_train)
    search_time = time.time() - start_time
    print(f"Recherche par grille termin√©e en {search_time:.2f} secondes")

    val_score = accuracy_score(y_val, grid_search.predict(X_val))
    print(f"Meilleurs hyperparam√®tres: {grid_search.best_params_}")
    print(f"Score de validation crois√©e: {grid_search.best_score_:.4f}")
    print(f"Score sur l'ensemble de validation: {val_score:.4f}")

    return grid_search.best_params_, val_score


def plot_training_metrics(
     train_accuracies, val_accuracies, train_losses, val_losses,
     train_f1s, val_f1s, train_recalls, val_recalls, n_epochs,
     algorithm_name="MLP", output_dir="figures/mlp"):
     """
     Fonction d√©di√©e pour tracer les m√©triques d'entra√Ænement et enregistrer chaque graphe dans un fichier s√©par√©.
     EXACTEMENT comme dans pasteCode.ipynb
     """
     # Style commun pour tous les graphiques
     metrics = {
          'Accuracy': (train_accuracies, val_accuracies),
          'Loss': (train_losses, val_losses),
          'F1 Score': (train_f1s, val_f1s),
          'Recall': (train_recalls, val_recalls)
     }

     for metric_name, (train_metric, val_metric) in metrics.items():
          fig, ax = plt.subplots(figsize=(10, 6))
          ax.grid(True, linestyle='--', alpha=0.7)
          ax.set_axisbelow(True)  # Placer la grille derri√®re les donn√©es

          # Graphique de la m√©trique
          ax.plot(range(1, n_epochs + 1), train_metric, '-o', label='Entra√Ænement', color='#1f77b4',
                    linewidth=2, markersize=5, alpha=0.8)
          ax.plot(range(1, n_epochs + 1), val_metric, '-o', label='Validation', color='#ff7f0e',
                    linewidth=2, markersize=5, alpha=0.8)
          ax.set_title(f'{algorithm_name} - {metric_name}', fontsize=16, fontweight='bold')
          ax.set_xlabel('√âpoque', fontsize=14)
          ax.set_ylabel(metric_name, fontsize=14)
          ax.legend(fontsize=12)

          # Ajouter des annotations pour les valeurs maximales (validation)
          max_val_metric = max(val_metric)
          max_val_metric_idx = val_metric.index(max_val_metric)
          ax.annotate(f'Max: {max_val_metric:.4f}',
                         xy=(max_val_metric_idx + 1, max_val_metric),
                         xytext=(max_val_metric_idx + 1, max_val_metric - 0.05),
                         arrowprops=dict(facecolor='black', shrink=0.05),
                         fontsize=12, ha='center')

          plt.tight_layout()

          # Assurer que le r√©pertoire de sortie existe
          os.makedirs(output_dir, exist_ok=True)
          output_path = os.path.join(output_dir, f'{algorithm_name.lower()}_{metric_name.lower().replace(" ", "_")}.png')
          plt.savefig(output_path, dpi=300, bbox_inches='tight')
          print(f"‚úÖ M√©triques d'entra√Ænement enregistr√©es dans {output_path}")
          plt.close(fig)


def train_mlp_progressive(X_train, y_train, X_val, y_val, X_test, y_test, best_params, n_epochs=25):
    """
    Entra√Æne le mod√®le MLP de mani√®re progressive en augmentant la taille de l'ensemble d'entra√Ænement
    EXACTEMENT comme dans pasteCode.ipynb avec l'entra√Ænement progressif pr√©f√©r√©
    """
    print(f"Entra√Ænement progressif du MLP sur {n_epochs} √©poques...")

    # Convertir en tableaux NumPy pour √©viter les probl√®mes d'indexation
    if not isinstance(X_train, np.ndarray):
        X_train = np.array(X_train)
    if not isinstance(y_train, np.ndarray):
        y_train = np.array(y_train)
    if not isinstance(X_val, np.ndarray):
        X_val = np.array(X_val)
    if not isinstance(y_val, np.ndarray):
        y_val = np.array(y_val)
    if not isinstance(X_test, np.ndarray):
        X_test = np.array(X_test)
    if not isinstance(y_test, np.ndarray):
        y_test = np.array(y_test)

    # V√©rifier si l'entra√Ænement est possible
    if len(X_train) == 0 or len(y_train) == 0:
        raise ValueError("Ensembles d'entra√Ænement vides")
    if len(np.unique(y_train)) < 2:
        raise ValueError("L'ensemble d'entra√Ænement doit contenir au moins deux classes diff√©rentes")

    # M√©triques (EXACTEMENT comme dans le notebook)
    train_accuracies = []
    val_accuracies = []
    train_precisions = []
    val_precisions = []
    train_recalls = []
    val_recalls = []
    train_f1s = []
    val_f1s = []
    train_losses = []
    val_losses = []
    epoch_train_sizes = []

    # Initialiser le mod√®le avec les meilleurs param√®tres
    model = MLPClassifier(**best_params, random_state=42)

    # Meilleur mod√®le
    best_model = None
    best_val_acc = 0

    # Valeurs pour l'augmentation progressive de la taille de l'ensemble d'entra√Ænement
    train_ratio_start = 0.2  # Commence avec 20% des donn√©es
    train_ratio_end = 1.0    # Termine avec 100% des donn√©es

    # Assurer une r√©partition √©quilibr√©e des classes lors de l'√©chantillonnage
    class_indices = {}
    unique_classes = np.unique(y_train)
    for cls in unique_classes:
        class_indices[cls] = np.where(y_train == cls)[0]

    with tqdm(total=n_epochs, desc="Entra√Ænement MLP") as pbar:
        for epoch in range(n_epochs):
            try:
                # Augmentation progressive de la taille de l'entra√Ænement
                train_ratio = train_ratio_start + (train_ratio_end - train_ratio_start) * (epoch / max(1, n_epochs-1))
                indices = []
                for cls in unique_classes:
                    n_samples = int(len(class_indices[cls]) * train_ratio)
                    if n_samples > 0:
                        cls_sample = np.random.choice(class_indices[cls], n_samples, replace=False)
                        indices.extend(cls_sample)
                np.random.shuffle(indices)
                train_size = len(indices)
                epoch_train_sizes.append(train_size)
                
                # Extraire les donn√©es d'entra√Ænement pour cette √©poque
                X_epoch = X_train[indices]
                y_epoch = y_train[indices]

                # Cr√©er et entra√Æner le mod√®le avec les meilleurs hyperparam√®tres
                model.fit(X_epoch, y_epoch)

                # √âvaluations
                train_pred = model.predict(X_epoch)
                val_pred = model.predict(X_val)

                train_acc = accuracy_score(y_epoch, train_pred)
                val_acc = accuracy_score(y_val, val_pred)
                train_prec = precision_score(y_epoch, train_pred, zero_division=0)
                val_prec = precision_score(y_val, val_pred, zero_division=0)
                train_rec = recall_score(y_epoch, train_pred, zero_division=0)
                val_rec = recall_score(y_val, val_pred, zero_division=0)
                train_f1 = f1_score(y_epoch, train_pred, zero_division=0)
                val_f1 = f1_score(y_val, val_pred, zero_division=0)

                train_accuracies.append(train_acc)
                val_accuracies.append(val_acc)
                train_precisions.append(train_prec)
                val_precisions.append(val_prec)
                train_recalls.append(train_rec)
                val_recalls.append(val_rec)
                train_f1s.append(train_f1)
                val_f1s.append(val_f1)

                # Calcul des pertes (log loss) si predict_proba est disponible
                if hasattr(model, 'predict_proba'):
                    try:
                        train_probs = model.predict_proba(X_epoch)
                        val_probs = model.predict_proba(X_val)
                        # V√©rifier la validit√© des probabilit√©s
                        if not np.any(np.isnan(train_probs)) and not np.any(np.isnan(val_probs)):
                            train_loss = log_loss(y_epoch, train_probs)
                            val_loss = log_loss(y_val, val_probs)
                        else:
                            train_loss = -np.log(max(0.001, train_acc))
                            val_loss = -np.log(max(0.001, val_acc))
                    except Exception:
                        # En cas d'erreur, utiliser une approximation
                        train_loss = -np.log(max(0.001, train_acc))
                        val_loss = -np.log(max(0.001, val_acc))
                else:
                    # Si predict_proba n'est pas disponible, simuler une relation inverse avec l'accuracy
                    train_loss = -np.log(max(0.001, train_acc))
                    val_loss = -np.log(max(0.001, val_acc))

                train_losses.append(train_loss)
                val_losses.append(val_loss)

                pbar.update(1)
                pbar.set_postfix({
                    'Train Acc': f'{train_acc:.4f}',
                    'Val Acc': f'{val_acc:.4f}',
                    'Train Size': train_size
                })

                # Suivre le meilleur mod√®le
                if val_acc > best_val_acc:
                    best_val_acc = val_acc
                    best_model = model

            except Exception as e:
                print(f"\nErreur √† l'√©poque {epoch+1}: {str(e)}")
                continue

    # Si aucun mod√®le valide n'a √©t√© trouv√©, utiliser un mod√®le par d√©faut
    if best_model is None:
        print("Aucun mod√®le valide trouv√© pendant l'entra√Ænement. Cr√©ation d'un mod√®le par d√©faut.")
        best_model = MLPClassifier(**best_params, random_state=42)
        best_model.fit(X_train, y_train)
    
    # Tracer les m√©triques d'entra√Ænement (EXACTEMENT comme dans le notebook)
    try:
        plot_training_metrics(train_accuracies, val_accuracies, train_losses, val_losses, 
                             train_f1s, val_f1s, train_recalls, val_recalls, n_epochs,
                             algorithm_name="MLP", output_dir="figures/mlp")
        
        # Graphique de la taille de l'ensemble d'entra√Ænement
        plt.figure(figsize=(10, 5))
        plt.plot(range(1, n_epochs+1), epoch_train_sizes, '-o', linewidth=2, markersize=4, color='#2ca02c')
        plt.title('Progression de la taille de l\'ensemble d\'entra√Ænement', fontsize=14, fontweight='bold')
        plt.xlabel('√âpoque', fontsize=12)
        plt.ylabel('Nombre d\'√©chantillons', fontsize=12)
        plt.grid(True, linestyle='--', alpha=0.7)
        plt.tight_layout()
        plt.savefig('figures/mlp/mlp_training_size.png', dpi=300)
        plt.close()
        print("‚úÖ Graphique de progression de taille sauvegard√©")
        
    except Exception as e:
        print(f"Erreur lors de la cr√©ation des graphiques: {str(e)}")

    # √âvaluation finale du meilleur mod√®le sur l'ensemble de test
    test_pred = best_model.predict(X_test)
    test_accuracy = accuracy_score(y_test, test_pred)
    test_precision = precision_score(y_test, test_pred, zero_division=0)
    test_recall = recall_score(y_test, test_pred, zero_division=0)
    test_f1 = f1_score(y_test, test_pred, zero_division=0)
    conf_matrix = confusion_matrix(y_test, test_pred)

    # Tracer la matrice de confusion pour le meilleur mod√®le
    try:
        plt.figure(figsize=(8, 6))
        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
                   xticklabels=['Normal', 'Attack'], yticklabels=['Normal', 'Attack'])
        plt.title('Matrice de confusion MLP (Ensemble de test)', fontsize=14, fontweight='bold')
        plt.xlabel('Classe pr√©dite', fontsize=12)
        plt.ylabel('Classe r√©elle', fontsize=12)
        plt.tight_layout()
        plt.savefig('figures/mlp/mlp_confusion_matrix.png', dpi=300)
        plt.close()
        print("‚úÖ Matrice de confusion sauvegard√©e")
    except Exception as e:
        print(f"Erreur lors de la cr√©ation de la matrice de confusion: {str(e)}")

    # **CRITIQUE**: Sauvegarder avec le nom attendu par le syst√®me
    try:
        joblib.dump(best_model, "models/mlp_best.pkl")
        print("‚úÖ Meilleur mod√®le MLP sauvegard√© dans models/mlp_best.pkl")
    except Exception as e:
        print(f"‚ùå Erreur lors de la sauvegarde du mod√®le: {str(e)}")

    # Afficher les r√©sultats finaux
    print("\n=== R√©sultats finaux ===")
    print(f"Accuracy sur l'ensemble de test: {test_accuracy:.4f}")
    print(f"Precision sur l'ensemble de test: {test_precision:.4f}")
    print(f"Recall sur l'ensemble de test: {test_recall:.4f}")
    print(f"F1-Score sur l'ensemble de test: {test_f1:.4f}")
    
    # Analyser la matrice de confusion
    tn, fp, fn, tp = conf_matrix.ravel()
    total = tn + fp + fn + tp
    print(f"\nD√©tail de la matrice de confusion:")
    print(f"  - Vrais N√©gatifs (TN): {tn} ({tn/total*100:.2f}%)")
    print(f"  - Faux Positifs (FP): {fp} ({fp/total*100:.2f}%)")
    print(f"  - Faux N√©gatifs (FN): {fn} ({fn/total*100:.2f}%)")
    print(f"  - Vrais Positifs (TP): {tp} ({tp/total*100:.2f}%)")
    print(f"  - Taux de faux positifs: {fp/(fp+tn)*100:.2f}%")
    print(f"  - Taux de faux n√©gatifs: {fn/(fn+tp)*100:.2f}%")

    # Retourner les informations d'apprentissage et le meilleur mod√®le
    return {
        'model': best_model,
        'train_accuracies': train_accuracies,
        'val_accuracies': val_accuracies,
        'train_losses': train_losses,
        'val_losses': val_losses,
        'train_precisions': train_precisions,
        'val_precisions': val_precisions,
        'train_recalls': train_recalls,
        'val_recalls': val_recalls,
        'train_f1s': train_f1s,
        'val_f1s': val_f1s,
        'epoch_train_sizes': epoch_train_sizes,
        'best_val_accuracy': best_val_acc,
        'test_accuracy': test_accuracy,
        'test_precision': test_precision,
        'test_recall': test_recall,
        'test_f1': test_f1,
        'confusion_matrix': conf_matrix
    }


def main(data_path="UNSW_NB15_training-set.csv", test_size=0.2, val_size=0.15, n_epochs=25, random_state=42):
    """
    Fonction principale qui ex√©cute tout le pipeline MLP
    EXACTEMENT comme dans pasteCode.ipynb
    """
    print("=" * 80)
    print("Pipeline d'analyse et d'entra√Ænement MLP pour la d√©tection d'intrusion r√©seau")
    print("Bas√© sur la m√©thode exacte de pasteCode.ipynb avec entra√Ænement progressif")
    print("=" * 80)
    
    start_time = time.time()
    
    try:
        # Charger et pr√©traiter les donn√©es
        X_train, X_val, X_test, y_train, y_val, y_test, scaler, label_encoders = load_and_preprocess_data(
            filepath=data_path, test_size=test_size, val_size=val_size, random_state=random_state
        )
        
        # Sauvegarder le scaler et les encodeurs (compatibilit√© avec le syst√®me)
        try:
            joblib.dump(scaler, "models/scaler.pkl")
            joblib.dump(label_encoders, "models/label_encoders.pkl")
            print("‚úÖ Scaler et encodeurs sauvegard√©s dans le dossier 'models/'")
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors de la sauvegarde du scaler et des encodeurs: {str(e)}")
        
        # Utiliser les meilleurs hyperparam√®tres trouv√©s dans le notebook
        print("\nüîß Configuration des hyperparam√®tres:")
        
        # Ces sont les hyperparam√®tres optimaux trouv√©s dans votre notebook
        best_params = {
            'activation': 'relu', 
            'alpha': 0.0001, 
            'hidden_layer_sizes': (128, 64), 
            'learning_rate': 'constant', 
            'solver': 'adam'
        }
        print(f"Utilisation des hyperparam√®tres optimaux: {best_params}")
        
        # Si vous voulez re-optimiser, d√©commentez ces lignes:
        # print("Optimisation des hyperparam√®tres...")
        # best_params, val_score = optimize_mlp_hyperparameters(X_train, y_train, X_val, y_val)
        
        # Entra√Ænement progressif (LA M√âTHODE PR√âF√âR√âE DU NOTEBOOK)
        print(f"\nü§ñ Entra√Ænement progressif du MLP (m√©thode du notebook):")
        results = train_mlp_progressive(X_train, y_train, X_val, y_val, X_test, y_test, best_params, n_epochs=n_epochs)
        
        # Affichage du temps total d'ex√©cution
        elapsed_time = time.time() - start_time
        print(f"\nTemps total d'ex√©cution: {elapsed_time:.2f} secondes ({elapsed_time/60:.2f} minutes)")
        
        # R√©sum√© des performances
        print(f"\nüìä R√©sum√© des performances:")
        print(f"  - Accuracy finale sur le test: {results['test_accuracy']:.4f}")
        print(f"  - Precision finale sur le test: {results['test_precision']:.4f}")
        print(f"  - Recall final sur le test: {results['test_recall']:.4f}")
        print(f"  - F1-Score final sur le test: {results['test_f1']:.4f}")
        print(f"  - Meilleure accuracy de validation: {results['best_val_accuracy']:.4f}")
        print(f"  - Hyperparam√®tres utilis√©s: {best_params}")
        
        # Information sur la compatibilit√©
        print(f"\nüéØ SUCC√àS - Mod√®le MLP compatible cr√©√©!")
        print(f"‚úÖ Sauvegard√© dans: models/mlp_best.pkl")
        print(f"‚úÖ Features: {X_train.shape[1]} (compatible avec le syst√®me)")
        print(f"‚úÖ M√©thode: Entra√Ænement progressif (comme dans pasteCode.ipynb)")
        print(f"‚úÖ Visualisations: G√©n√©r√©es dans figures/mlp/")
        
        # √âmettre un bip de succ√®s
        try:
            winsound.Beep(1000, 500)  # Bip de succ√®s
        except:
            pass
        
        return results
    
    except Exception as e:
        print(f"\n‚ùå Erreur lors de l'ex√©cution du pipeline: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    # Point d'entr√©e du script
    print("üöÄ D√©marrage du re-entra√Ænement MLP avec la m√©thode du notebook")
    
    # V√©rifier si le fichier de donn√©es existe
    data_path = "UNSW_NB15_training-set.csv"
    if not os.path.exists(data_path):
        print(f"‚ö†Ô∏è Le fichier {data_path} n'existe pas. Veuillez sp√©cifier le chemin correct.")
        exit(1)
    
    # Ex√©cuter le pipeline principal avec la m√©thode du notebook
    results = main(data_path=data_path, n_epochs=25)
    
    if results:
        print("\nüéâ SUCCESS! Re-entra√Ænement MLP termin√© avec la m√©thode du notebook!")
        print("üîÑ Le mod√®le MLP est maintenant compatible et pr√™t √† √™tre utilis√© dans votre syst√®me.")
        print("üìù Remplacez l'ancien models/mlp_best.pkl - le nouveau est compatible avec 42 features.")
    else:
        print("\nüòû Le re-entra√Ænement a √©chou√©. V√©rifiez les erreurs ci-dessus.")
