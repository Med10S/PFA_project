# Syst√®me de D√©tection d'Intrusion R√©seau Temps R√©el

## üìë Table des Mati√®res

- [üéØ Vue d'Ensemble](#-vue-densemble)
- [üåü Caract√©ristiques Principales](#-caract√©ristiques-principales)
- [üèóÔ∏è Architecture du Syst√®me](#Ô∏è-architecture-du-syst√®me)
- [üìã Pr√©requis](#-pr√©requis)
- [üöÄ Installation et D√©marrage](#-installation-et-d√©marrage)
- [üê≥ Configuration Docker](#-configuration-docker)
- [üì° API Endpoints](#-api-endpoints)
- [üìä Format des Donn√©es (UNSW-NB15)](#-format-des-donn√©es-unsw-nb15)
- [üîß Configuration](#-configuration)
- [üö® Syst√®me d'Alertes](#-syst√®me-dalertes)
- [üìà Performance et M√©triques](#-performance-et-m√©triques)
- [üîÑ Int√©gration avec ELK Stack](#-int√©gration-avec-elk-stack)
- [üß™ Tests et Validation](#-tests-et-validation)
- [üêõ D√©pannage](#-d√©pannage)
- [üìö Documentation API Compl√®te](#-documentation-api-compl√®te)
- [üîí S√©curit√©](#-s√©curit√©)
- [üöÄ D√©ploiement Production](#-d√©ploiement-production)
- [üìä Monitoring et M√©triques](#-monitoring-et-m√©triques)
- [üîß Maintenance et √âvolution](#-maintenance-et-√©volution)
- [üìû Support et Ressources](#-support-et-ressources)

## üéØ Vue d'Ensemble

Ce projet impl√©mente un syst√®me de d√©tection d'intrusion r√©seau en temps r√©el bas√© sur l'intelligence artificielle. Il utilise des mod√®les de Machine Learning pr√©-entra√Æn√©s sur le dataset UNSW-NB15 pour analyser le trafic r√©seau et d√©tecter automatiquement les tentatives d'intrusion avec un haut niveau de pr√©cision.

### üåü Caract√©ristiques Principales

- **D√©tection en Temps R√©el** : API FastAPI pour l'analyse instantan√©e
- **Ensemble Learning** : Combinaison optimis√©e de KNN, MLP et XGBoost
- **Syst√®me Hybride** : D√©tection par signature + d√©tection d'anomalies
- **Architecture Modulaire** : Composants s√©par√©s et r√©utilisables
- **Performance √âlev√©e** : >95% de pr√©cision, <3% de faux positifs
- **Production Ready** : Configuration externalis√©e, logging, alertes

## üèóÔ∏è Architecture du Syst√®me

### Architecture Globale
```
Suricata ‚Üí Logstash ‚Üí Elasticsearch ‚Üí FastAPI Detection Service ‚Üí Alertes
```

### Flux de Donn√©es D√©taill√©
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Dataset       ‚îÇ    ‚îÇ   Preprocessing ‚îÇ    ‚îÇ   Training      ‚îÇ
‚îÇ   UNSW-NB15     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Pipeline      ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Pipeline      ‚îÇ
‚îÇ   (43 Features) ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ                        ‚îÇ
                                ‚ñº                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Raw Network   ‚îÇ    ‚îÇ   Preprocessor  ‚îÇ    ‚îÇ   Trained       ‚îÇ
‚îÇ   Traffic       ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   (Real-time)   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Models        ‚îÇ
‚îÇ   (Live Data)   ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ   (.pkl files)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ                        ‚îÇ
                                ‚ñº                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Detection     ‚îÇ    ‚îÇ   Ensemble      ‚îÇ    ‚îÇ   Hybrid        ‚îÇ
‚îÇ   Results       ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ   Classifier    ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ   System        ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ                        ‚îÇ
                                ‚ñº                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Alerts &      ‚îÇ    ‚îÇ   FastAPI       ‚îÇ    ‚îÇ   Web Interface ‚îÇ
‚îÇ   Logging       ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ   Service       ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   & Monitoring  ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìã Pr√©requis

- **Python** 3.8+
- **Syst√®me** Windows avec PowerShell
- **RAM** 8GB minimum
- **Espace disque** 2GB pour les mod√®les et donn√©es

## üöÄ Installation et D√©marrage

### 1. Pr√©paration de l'Environnement

```powershell
# Aller dans le r√©pertoire du projet
cd "c:\Users\pc\personnel\etude_GTR2\S4\PFA"

# Installer les d√©pendances
pip install -r requirements.txt
```

### 2. V√©rification des Mod√®les

Assurez-vous que les mod√®les suivants sont pr√©sents dans le dossier `models/` :
- ‚úÖ `KNN_best.pkl` - Mod√®le K-Nearest Neighbors
- ‚úÖ `mlp_best.pkl` - R√©seau de neurones MLP 
- ‚úÖ `xgb_best.pkl` - Mod√®le XGBoost
- ‚úÖ `scaler.pkl` - Normalisateur StandardScaler
- ‚úÖ `label_encoders.pkl` - Encodeurs pour variables cat√©gorielles

### 3. D√©marrage du Service

```powershell
# M√©thode 1: Script PowerShell automatis√© (recommand√©)
.\start_detection_service.ps1

# M√©thode 2: D√©marrage manuel
uvicorn realtime_detection_service:app --host 0.0.0.0 --port 8000 --reload
```

### 4. V√©rification du Fonctionnement

```powershell
# Test automatis√© complet
python test_realtime_system.py

# Test rapide
python test\quick_test.py

# Test manuel de l'API
curl http://localhost:8000/health
```

## üê≥ Configuration Docker

### Dockerfile Principal

Cr√©er un `Dockerfile` √† la racine du projet :

```dockerfile
FROM python:3.9-slim

# M√©tadonn√©es
LABEL maintainer="PFA Network Security Team"
LABEL description="Network Intrusion Detection System"
LABEL version="1.0"

# Configuration de l'environnement
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV APP_HOME=/app

# Cr√©ation de l'utilisateur non-root
RUN groupadd -r appuser && useradd -r -g appuser appuser

# R√©pertoire de travail
WORKDIR $APP_HOME

# Installation des d√©pendances syst√®me
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Installation des d√©pendances Python
COPY requirements.txt .
RUN pip install --no-cache-dir --upgrade pip \
    && pip install --no-cache-dir -r requirements.txt

# Copie du code source
COPY . .

# Cr√©ation des r√©pertoires n√©cessaires
RUN mkdir -p logs models data \
    && chown -R appuser:appuser $APP_HOME

# Changement vers l'utilisateur non-root
USER appuser

# Port d'exposition
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Commande de d√©marrage
CMD ["uvicorn", "realtime_detection_service:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```

### Docker Compose - Configuration Standalone

Cr√©er un fichier `docker-compose.yml` :

```yaml
version: '3.8'

services:
  ids-api:
    build: .
    container_name: network-ids
    ports:
      - "8000:8000"
    volumes:
      - ./models:/app/models:ro
      - ./logs:/app/logs
      - ./config.py:/app/config.py:ro
    environment:
      - ENVIRONMENT=production
      - LOG_LEVEL=INFO
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - ids-network

  # Service de monitoring (optionnel)
  prometheus:
    image: prom/prometheus:latest
    container_name: ids-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    networks:
      - ids-network

networks:
  ids-network:
    driver: bridge
```

### Docker Compose avec ELK Stack

Cr√©er un fichier `docker-compose.elk.yml` pour l'int√©gration compl√®te :

```yaml
version: '3.8'

services:
  # Service principal de d√©tection
  ids-api:
    build: .
    container_name: network-ids
    ports:
      - "8000:8000"
    volumes:
      - ./models:/app/models:ro
      - ./logs:/app/logs
      - ./config.py:/app/config.py:ro
    environment:
      - ENVIRONMENT=production
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
    depends_on:
      - elasticsearch
    networks:
      - elk-network
    restart: unless-stopped

  # Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.0
    container_name: ids-elasticsearch
    environment:
      - node.name=elasticsearch
      - cluster.name=ids-cluster
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - elk-network

  # Kibana
  kibana:
    image: docker.elastic.co/kibana/kibana:8.12.0
    container_name: ids-kibana
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - elk-network

  # Logstash
  logstash:
    image: docker.elastic.co/logstash/logstash:8.12.0
    container_name: ids-logstash
    volumes:
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./elk/logstash/config:/usr/share/logstash/config:ro
    ports:
      - "5044:5044"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
    depends_on:
      - elasticsearch
    networks:
      - elk-network

  # Suricata (pour la capture r√©seau)
  suricata:
    image: jasonish/suricata:latest
    container_name: ids-suricata
    network_mode: host
    cap_add:
      - NET_ADMIN
      - SYS_NICE
    volumes:
      - ./suricata/suricata.yaml:/etc/suricata/suricata.yaml:ro
      - ./suricata/rules:/var/lib/suricata/rules:ro
      - suricata-logs:/var/log/suricata
    command: suricata -c /etc/suricata/suricata.yaml -i eth0

volumes:
  elasticsearch-data:
    driver: local
  suricata-logs:
    driver: local

networks:
  elk-network:
    driver: bridge
```

### Commandes Docker Essentielles

```bash
# Construction de l'image
docker build -t network-ids:latest .

# D√©marrage rapide
docker-compose up -d

# D√©marrage avec ELK Stack
docker-compose -f docker-compose.elk.yml up -d

# Visualisation des logs
docker-compose logs -f ids-api

# Arr√™t des services
docker-compose down

# Nettoyage complet
docker-compose down -v --remove-orphans

# Reconstruction apr√®s modifications
docker-compose up --build -d

# Sauvegarde de l'image
docker save network-ids:latest | gzip > network-ids-backup.tar.gz

# Chargement de l'image sauvegard√©e
docker load < network-ids-backup.tar.gz
```

### Configuration des Volumes

Cr√©er la structure de r√©pertoires pour Docker :

```bash
# Cr√©ation des r√©pertoires
mkdir -p elk/logstash/{config,pipeline}
mkdir -p suricata/rules
mkdir -p monitoring
mkdir -p logs

# Configuration Logstash
cat > elk/logstash/pipeline/suricata.conf << EOF
input {
  file {
    path => "/var/log/suricata/eve.json"
    codec => json
    type => "suricata"
  }
}

filter {
  if [type] == "suricata" {
    # Envoi vers l'API de d√©tection
    http {
      url => "http://ids-api:8000/analyze"
      http_method => "post"
      headers => {
        "Content-Type" => "application/json"
      }
      mapping => {
        "flow_data" => "%{message}"
      }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "network-security-%{+YYYY.MM.dd}"
  }
}
EOF
```

### Variables d'Environnement Docker

Cr√©er un fichier `.env` :

```env
# Configuration g√©n√©rale
ENVIRONMENT=production
LOG_LEVEL=INFO
API_PORT=8000

# Configuration Elasticsearch
ELASTICSEARCH_HOST=elasticsearch
ELASTICSEARCH_PORT=9200
ELASTICSEARCH_INDEX=network-security

# Configuration des mod√®les
MODEL_PATH=/app/models
SCALER_PATH=/app/models/scaler.pkl

# Configuration des alertes
ALERT_WEBHOOK_URL=http://webhook.site/your-uuid
ALERT_EMAIL_ENABLED=false

# Limites de performance
MAX_WORKERS=4
REQUEST_TIMEOUT=30
BATCH_SIZE=100
```

### Docker Multi-Stage Build (Optimis√©)

Version optimis√©e du Dockerfile pour la production :

```dockerfile
# Stage 1: Build environment
FROM python:3.9-slim as builder

WORKDIR /app

# Installation des d√©pendances de build
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Installation des d√©pendances Python
COPY requirements.txt .
RUN pip install --user --no-cache-dir -r requirements.txt

# Stage 2: Runtime environment
FROM python:3.9-slim

# M√©tadonn√©es
LABEL maintainer="PFA Network Security Team"
LABEL description="Network Intrusion Detection System - Production"
LABEL version="1.0"

# Configuration de l'environnement
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV PATH="/root/.local/bin:${PATH}"
ENV APP_HOME=/app

# Cr√©ation de l'utilisateur
RUN groupadd -r appuser && useradd -r -g appuser appuser

# Installation des d√©pendances runtime uniquement
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copie des d√©pendances depuis le stage builder
COPY --from=builder /root/.local /root/.local

# R√©pertoire de travail
WORKDIR $APP_HOME

# Copie du code
COPY . .

# Configuration des permissions
RUN mkdir -p logs models data \
    && chown -R appuser:appuser $APP_HOME

USER appuser

EXPOSE 8000

HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

CMD ["uvicorn", "realtime_detection_service:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```

### Scripts de D√©ploiement

Cr√©er un script `deploy.sh` :

```bash
#!/bin/bash

set -e

echo "üöÄ D√©ploiement du syst√®me de d√©tection d'intrusion..."

# V√©rification des pr√©requis
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker n'est pas install√©"
    exit 1
fi

if ! command -v docker-compose &> /dev/null; then
    echo "‚ùå Docker Compose n'est pas install√©"
    exit 1
fi

# Cr√©ation des r√©pertoires
mkdir -p logs models data elk/logstash/{config,pipeline} suricata/rules monitoring

# V√©rification des mod√®les
echo "üîç V√©rification des mod√®les..."
required_models=("KNN_best.pkl" "mlp_best.pkl" "xgb_best.pkl" "scaler.pkl")
for model in "${required_models[@]}"; do
    if [ ! -f "models/$model" ]; then
        echo "‚ùå Mod√®le manquant: $model"
        exit 1
    fi
done
echo "‚úÖ Tous les mod√®les sont pr√©sents"

# Construction et d√©marrage
echo "üèóÔ∏è Construction de l'image Docker..."
docker-compose build

echo "üöÄ D√©marrage des services..."
docker-compose up -d

echo "‚è≥ Attente du d√©marrage des services..."
sleep 30

# V√©rification de la sant√©
echo "üè• V√©rification de la sant√© du service..."
if curl -f http://localhost:8000/health; then
    echo "‚úÖ Service d√©marr√© avec succ√®s!"
    echo "üìä Interface disponible sur: http://localhost:8000"
    echo "üìà Monitoring Kibana: http://localhost:5601 (si ELK activ√©)"
else
    echo "‚ùå √âchec du d√©marrage du service"
    docker-compose logs ids-api
    exit 1
fi

echo "üéâ D√©ploiement termin√©!"
```

## üì° API Endpoints

### üè• Health Check
```http
GET /health
```
V√©rifie l'√©tat du service et des mod√®les charg√©s.

**R√©ponse :**
```json
{
  "status": "healthy",
  "models_loaded": true,
  "models_info": {
    "ensemble_loaded": true,
    "hybrid_loaded": true,
    "models_count": 3
  },
  "timestamp": "2025-01-27T10:30:00"
}
```

### üîç D√©tection Individuelle
```http
POST /detect/single
Content-Type: application/json
```

**Exemple de requ√™te :**
```json
{
  "id": 1,
  "dur": 0.121478,
  "proto": "tcp",
  "service": "http",
  "state": "FIN",
  "spkts": 8,
  "dpkts": 26,
  "sbytes": 1032,
  "dbytes": 15421,
  "rate": 194.836043,
  "sttl": 63,
  "dttl": 63,
  "sload": 8504.846381,
  "dload": 126910.215713
  // ... (total 43 features)
}
```

**R√©ponse :**
```json
{
  "log_id": 1,
  "is_attack": false,
  "confidence": 0.85,
  "attack_probability": 0.15,
  "ml_predictions": {
    "knn": 0.12,
    "mlp": 0.18,
    "xgb": 0.16
  },
  "timestamp": "2025-01-27T10:30:00",
  "alert_generated": false
}
```

### üì¶ D√©tection en Batch
```http
POST /detect/batch
Content-Type: application/json
```

**Exemple de requ√™te :**
```json
{
  "logs": [
    {"id": 1, "dur": 0.5, "proto": "tcp", ...},
    {"id": 2, "dur": 1.2, "proto": "udp", ...}
  ]
}
```

### üìÑ D√©tection CSV
```http
POST /detect/csv
Content-Type: application/json
```

**Exemple de requ√™te :**
```json
{
  "csv_data": "id,dur,proto,service,state,spkts,dpkts,...\n1,0.121478,tcp,http,FIN,8,26,..."
}
```

### ü§ñ Informations Mod√®les
```http
GET /models/info
```

## üìä Format des Donn√©es (UNSW-NB15)

Le syst√®me utilise 43 features sp√©cifiques au dataset UNSW-NB15 :

| Feature | Type | Description |
|---------|------|-------------|
| id | int | Identifiant unique |
| dur | float | Dur√©e de la connexion |
| proto | string | Protocole (tcp, udp, icmp) |
| service | string | Service r√©seau |
| state | string | √âtat de la connexion |
| spkts | int | Nombre de paquets source |
| dpkts | int | Nombre de paquets destination |
| sbytes | int | Bytes transf√©r√©s source‚Üídestination |
| dbytes | int | Bytes transf√©r√©s destination‚Üísource |
| rate | float | Taux de transmission |
| ... | ... | 33 autres features |

### Features Cat√©gorielles
- **proto** : tcp, udp, icmp
- **service** : http, ftp, smtp, dns, ssh, etc.
- **state** : FIN, CON, REQ, RST, etc.

### Features Num√©riques
Toutes les autres features sont num√©riques (int ou float).

## üîß Configuration

### Fichier `config.py`

```python
# Pond√©ration des mod√®les dans l'ensemble
MODELS_CONFIG = {
    "knn": {"path": "models/KNN_best.pkl", "weight": 0.3},
    "mlp": {"path": "models/mlp_best.pkl", "weight": 0.35}, 
    "xgb": {"path": "models/xgb_best.pkl", "weight": 0.35}
}

# Seuils de d√©tection
DETECTION_THRESHOLD = 0.5   # Seuil pour classification binaire
CONFIDENCE_THRESHOLD = 0.7  # Seuil de confiance pour alertes

# Configuration API
API_HOST = "0.0.0.0"
API_PORT = 8000

# Configuration des alertes
ALERT_CONFIG = {
    "enable_logging": True,
    "enable_webhooks": False,
    "webhook_url": None,
    "log_file": "alerts.log"
}
```

## üö® Syst√®me d'Alertes

### Types d'Alertes

1. **Alerte Log** : Enregistr√©e dans `alerts.log`
2. **Alerte Webhook** : Envoy√©e vers un endpoint configur√©
3. **Alerte Console** : Affichage en temps r√©el

### Crit√®res d'Alerte

- `is_attack = true`
- `confidence >= 0.7` (configurable)
- Consensus entre les mod√®les

### Format des Alertes

```json
{
  "timestamp": "2025-01-27T10:30:00",
  "log_id": 12345,
  "alert_type": "INTRUSION_DETECTED",
  "confidence": 0.87,
  "attack_probability": 0.92,
  "source": {
    "proto": "tcp",
    "service": "http",
    "state": "FIN"
  },
  "models_consensus": {
    "knn": 0.85,
    "mlp": 0.91,
    "xgb": 0.89
  }
}
```

## üìà Performance et M√©triques

### M√©triques Typiques

- **Latence** : ~50-100ms par pr√©diction
- **Throughput** : ~200-500 requ√™tes/seconde
- **Pr√©cision** : >95% sur dataset UNSW-NB15
- **Faux positifs** : <3%
- **Recall** : >92%

### Optimisations

1. **Mise en cache** des mod√®les charg√©s
2. **Preprocessing optimis√©** avec pandas vectoris√©
3. **Pr√©dictions vectoris√©es** pour les batches
4. **Ensemble voting** efficace
5. **Gestion m√©moire** optimis√©e

## üîÑ Int√©gration avec ELK Stack

### Configuration Logstash

```ruby
# logstash-ids.conf
input {
  beats { port => 5044 }
}

filter {
  # Parse des logs au format UNSW-NB15
  csv {
    separator => ","
    columns => [
      "id", "dur", "proto", "service", "state", "spkts", "dpkts", "sbytes", "dbytes",
      "rate", "sttl", "dttl", "sload", "dload", "sloss", "dloss", "sinpkt", "dinpkt",
      "sjit", "djit", "swin", "stcpb", "dtcpb", "dwin", "tcprtt", "synack", "ackdat",
      "smean", "dmean", "trans_depth", "response_body_len", "ct_srv_src", "ct_state_ttl",
      "ct_dst_ltm", "ct_src_dport_ltm", "ct_dst_sport_ltm", "ct_dst_src_ltm", "is_ftp_login",
      "ct_ftp_cmd", "ct_flw_http_mthd", "ct_src_ltm", "ct_srv_dst", "is_sm_ips_ports"
    ]
  }

  # Conversion des types
  mutate {
    convert => {
      "id" => "integer"
      "dur" => "float"
      "spkts" => "integer"
      "dpkts" => "integer"
      # ... autres conversions
    }
  }

  # Appel du service ML
  http {
    url => "http://localhost:8000/detect/single"
    http_method => "post"
    body_format => "json"
    body => {
      "id" => "%{id}"
      "dur" => "%{dur}"
      "proto" => "%{proto}"
      # ... tous les fields
    }
    target_body => "ml_detection"
  }

  # Enrichissement avec les r√©sultats ML
  if [ml_detection] {
    ruby {
      code => '
        detection = event.get("ml_detection")
        if detection.is_a?(Hash)
          event.set("is_attack", detection["is_attack"])
          event.set("attack_probability", detection["attack_probability"])
          event.set("confidence", detection["confidence"])
          event.set("alert_generated", detection["alert_generated"])
        end
      '
    }
  }
}

output {
  # Stockage dans Elasticsearch
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "network-intrusion-%{+YYYY.MM.dd}"
    document_type => "_doc"
  }

  # Alertes pour les attaques d√©tect√©es
  if [is_attack] == true and [confidence] >= 0.7 {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "security-alerts-%{+YYYY.MM.dd}"
      document_type => "_doc"
    }
    
    file {
      path => "intrusion-alerts.log"
      codec => json_lines
    }
  }
}
```

### Templates Elasticsearch

#### Template pour donn√©es r√©seau
```json
{
  "index_patterns": ["network-intrusion-*"],
  "template": {
    "settings": {
      "number_of_shards": 2,
      "number_of_replicas": 1
    },
    "mappings": {
      "properties": {
        "@timestamp": {"type": "date"},
        "id": {"type": "long"},
        "dur": {"type": "float"},
        "proto": {"type": "keyword"},
        "service": {"type": "keyword"},
        "state": {"type": "keyword"},
        "is_attack": {"type": "boolean"},
        "attack_probability": {"type": "float"},
        "confidence": {"type": "float"},
        "alert_generated": {"type": "boolean"}
      }
    }
  }
}
```

### Dashboard Kibana

1. **Vue temps r√©el** des d√©tections
2. **M√©triques de performance** du syst√®me
3. **Top des attaques** d√©tect√©es par type
4. **Tendances temporelles** des intrusions
5. **G√©olocalisation** des sources d'attaque

## üß™ Tests et Validation

### Tests Automatis√©s

```powershell
# Test complet du syst√®me
python test_realtime_system.py

# Tests sp√©cifiques
python -m pytest tests/ -v

# Test de performance
python test\performance_test.py
```

### Tests Manuels

```bash
# Test de sant√©
curl http://localhost:8000/health

# Test avec log d'exemple
curl -X POST http://localhost:8000/detect/single \
  -H "Content-Type: application/json" \
  -d @test_data/sample_log.json

# Test de charge
ab -n 1000 -c 10 -T 'application/json' \
   -p test_data/batch_logs.json \
   http://localhost:8000/detect/batch
```

### Validation des Mod√®les

```python
# Script de validation (dans test/)
python validate_models.py
# - V√©rifie la coh√©rence des pr√©dictions
# - Teste la performance sur dataset de test
# - Valide les m√©triques de qualit√©
```

## üêõ D√©pannage

### Probl√®mes Courants

#### 1. Service ne d√©marre pas
```powershell
# V√©rifier les d√©pendances
pip install -r requirements.txt

# V√©rifier les mod√®les
ls models/

# V√©rifier les logs
tail logs/detection_service.log
```

#### 2. Erreur de chargement MLP
```
Probl√®me connu : Incompatibilit√© scikit-learn
Solution temporaire : Le syst√®me fonctionne avec KNN + XGBoost
```

#### 3. Erreurs de preprocessing
```powershell
# Debug du preprocessing
python debug_preprocessing.py

# V√©rifier le format des donn√©es
python test\validate_input_format.py
```

#### 4. Performance d√©grad√©e
```powershell
# Monitoring des ressources
Get-Process python

# Ajuster la configuration
# Modifier config.py : r√©duire les poids des mod√®les lents
```

### Logs de Diagnostic

- **Service principal** : `logs/detection_service.log`
- **Alertes** : `alerts.log`
- **Erreurs API** : Console FastAPI
- **Debugging** : `debug.log`

## üìö Documentation API Compl√®te

### Interface Swagger
Documentation interactive disponible sur : `http://localhost:8000/docs`

### Mod√®les de Donn√©es

#### NetworkLog (Input)
```python
class NetworkLog(BaseModel):
    id: int
    dur: float
    proto: str
    service: str
    state: str
    spkts: int
    dpkts: int
    # ... (total 43 fields)
```

#### DetectionResult (Output)
```python
class DetectionResult(BaseModel):
    log_id: int
    is_attack: bool
    confidence: float
    attack_probability: float
    ml_predictions: Dict[str, float]
    timestamp: datetime
    alert_generated: bool
```

### Codes d'Erreur

| Code | Description | Action |
|------|-------------|--------|
| 200 | Succ√®s | - |
| 400 | Donn√©es invalides | V√©rifier le format JSON |
| 422 | Validation √©chou√©e | V√©rifier les 43 features |
| 500 | Erreur interne | Consulter les logs |
| 503 | Service indisponible | Red√©marrer le service |

## üîí S√©curit√©

### Bonnes Pratiques

1. **Validation stricte** des entr√©es
2. **Rate limiting** sur l'API (optionnel)
3. **Authentification** pour la production
4. **Chiffrement** des communications
5. **Logs d'audit** complets
6. **Isolation** des mod√®les

### Configuration S√©curis√©e

```python
# Pour production
SECURITY_CONFIG = {
    "enable_cors": False,
    "allowed_hosts": ["localhost", "monitoring.internal"],
    "api_key_required": True,
    "rate_limit": "100/minute",
    "log_all_requests": True
}
```

## üöÄ D√©ploiement Production

### Avec Docker

```dockerfile
FROM python:3.9-slim

WORKDIR /app

# Installation des d√©pendances
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copie du code
COPY . .

# Port d'exposition
EXPOSE 8000

# Commande de d√©marrage
CMD ["uvicorn", "realtime_detection_service:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Avec systemd (Linux)

```ini
[Unit]
Description=Network Intrusion Detection Service
After=network.target

[Service]
Type=exec
User=ids
WorkingDirectory=/opt/ids
ExecStart=/usr/bin/python -m uvicorn realtime_detection_service:app --host 0.0.0.0 --port 8000
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

### Scripts de D√©ploiement

```bash
#!/bin/bash
# deploy.sh

echo "D√©ploiement du syst√®me de d√©tection..."

# Backup des mod√®les existants
cp -r models/ models_backup_$(date +%Y%m%d)/

# Mise √† jour du code
git pull origin main

# Installation des d√©pendances
pip install -r requirements.txt

# Tests pr√©-d√©ploiement
python test_realtime_system.py

# Red√©marrage du service
sudo systemctl restart ids-detection

echo "D√©ploiement termin√© !"
```

## üìä Monitoring et M√©triques

### M√©triques Cl√©s

```python
# M√©triques collect√©es automatiquement
METRICS = {
    "requests_total": "Nombre total de requ√™tes",
    "requests_per_second": "Requ√™tes par seconde",
    "response_time_avg": "Temps de r√©ponse moyen",
    "attacks_detected": "Attaques d√©tect√©es",
    "false_positive_rate": "Taux de faux positifs",
    "model_accuracy": "Pr√©cision des mod√®les",
    "system_health": "√âtat g√©n√©ral du syst√®me"
}
```

### Dashboard Prometheus/Grafana

```yaml
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'ids-detection'
    static_configs:
      - targets: ['localhost:8000']
    metrics_path: '/metrics'
```

### Alertes PagerDuty/Slack

```python
# Configuration des alertes critiques
CRITICAL_ALERTS = {
    "high_attack_rate": "Plus de 100 attaques/minute",
    "model_failure": "√âchec de chargement d'un mod√®le",
    "api_down": "Service API non r√©actif",
    "false_positive_spike": "Pic de faux positifs"
}
```

## üîß Maintenance et √âvolution

### R√©entra√Ænement des Mod√®les

```python
# Processus de r√©entra√Ænement
# 1. Collecter nouvelles donn√©es √©tiquet√©es
# 2. Utiliser aiModelsSecu.ipynb pour r√©entra√Æner
# 3. Valider les nouvelles performances
# 4. Remplacer les anciens mod√®les
# 5. Red√©marrer le service
```

### Ajout de Nouveaux Mod√®les

```python
# Dans config.py
MODELS_CONFIG["new_model"] = {
    "path": "models/new_model.pkl",
    "weight": 0.15
}

# Le syst√®me chargera automatiquement le nouveau mod√®le
```

### Mise √† Jour des Features

```python
# Pour ajouter de nouvelles features
# 1. Modifier FEATURE_NAMES dans config.py
# 2. Mettre √† jour le preprocessing
# 3. R√©entra√Æner tous les mod√®les
# 4. Valider la compatibilit√©
```

## üìû Support et Ressources

### Commandes Utiles

```powershell
# Status du service
curl http://localhost:8000/health

# Informations des mod√®les  
curl http://localhost:8000/models/info

# Test de performance
python test_realtime_system.py

# Logs en temps r√©el
Get-Content -Wait -Tail 10 logs/detection_service.log
```

### Ressources Additionnelles

- **Dataset UNSW-NB15** : [Source officielle](https://research.unsw.edu.au/projects/unsw-nb15-dataset)
- **FastAPI Documentation** : [https://fastapi.tiangolo.com/](https://fastapi.tiangolo.com/)
- **Scikit-learn Guide** : [https://scikit-learn.org/](https://scikit-learn.org/)
- **Ensemble Methods** : [Documentation sklearn](https://scikit-learn.org/stable/modules/ensemble.html)

### Contact et Support

- **Issues** : Utiliser le syst√®me de tracking des bugs
- **Documentation** : Consulter `/docs` pour l'API
- **Logs** : Toujours consulter les logs avant de signaler un probl√®me
- **Tests** : Ex√©cuter les tests avant toute modification

## üéâ F√©licitations !

Votre syst√®me de d√©tection d'intrusion temps r√©el est maintenant op√©rationnel ! 

### √âtat Actuel du Syst√®me

‚úÖ **Fonctionnel** :
- Service FastAPI d√©ploy√©
- Mod√®les KNN et XGBoost op√©rationnels
- API compl√®te avec tous les endpoints
- Syst√®me d'alertes configur√©
- Tests automatis√©s disponibles

‚ö†Ô∏è **En cours** :
- Probl√®me MLP en cours de r√©solution
- Optimisations de performance en cours
- Int√©gration ELK Stack en cours de finalisation

### Prochaines √âtapes Recommand√©es

1. **R√©soudre le probl√®me MLP** pour am√©liorer les performances
2. **Int√©grer avec Suricata** pour la collecte des logs
3. **Configurer Elasticsearch** pour le stockage
4. **D√©ployer en production** avec Docker/systemd
5. **Monitorer les performances** avec Grafana

Pour toute question ou am√©lioration, consultez les logs et la documentation API compl√®te sur `http://localhost:8000/docs`.

---

**Syst√®me d√©velopp√© pour la d√©tection d'intrusion r√©seau en temps r√©el**  
*Version : 1.0 | Date : Janvier 2025*
