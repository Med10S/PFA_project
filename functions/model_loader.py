"""
Chargeur de modÃ¨les pour le systÃ¨me de dÃ©tection temps rÃ©el
"""

import joblib
import pickle
import logging
from pathlib import Path
from typing import Dict, Any, Optional
from sklearn.ensemble import IsolationForest

from config import MODELS_CONFIG, SCALER_PATH, LABEL_ENCODERS_PATH
from ensemble_models import AdvancedEnsembleClassifier, HybridDetectionSystem
from functions.preprocessing import RealtimePreprocessor

logger = logging.getLogger(__name__)

class ModelLoader:
    """
    Classe pour charger tous les modÃ¨les et prÃ©processeurs
    """
    
    def __init__(self):
        self.models = {}
        self.scaler = None
        self.label_encoders = {}
        self.ensemble_classifier = None
        self.hybrid_system = None
        self.preprocessor = None
        self.is_loaded = False
        
    def load_all_models(self) -> bool:
        """
        Charge tous les modÃ¨les et prÃ©processeurs
        """
        try:
            logger.info("ğŸ”„ Chargement des modÃ¨les...")
            
            # 1. Charger les modÃ¨les individuels
            self._load_individual_models()
            
            # 2. Charger les prÃ©processeurs
            self._load_preprocessors()
            
            # 3. CrÃ©er l'ensemble classifier
            self._create_ensemble_classifier()
            
            # 4. CrÃ©er le systÃ¨me hybride
            self._create_hybrid_system()
            
            # 5. Initialiser le preprocessor
            self._initialize_preprocessor()
            
            self.is_loaded = True
            logger.info("âœ… Tous les modÃ¨les chargÃ©s avec succÃ¨s")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Erreur chargement des modÃ¨les: {e}")
            return False
    
    def _load_individual_models(self):
        """Charge les modÃ¨les individuels"""
        logger.info("ğŸ“‚ Chargement des modÃ¨les individuels...")
        
        for model_name, config in MODELS_CONFIG.items():
            model_path = config["path"]
            
            if model_path.exists():
                try:
                    model = joblib.load(model_path)
                    self.models[model_name] = model
                    logger.info(f"  âœ… {model_name} chargÃ© depuis {model_path}")
                except Exception as e:
                    logger.warning(f"  âš ï¸ Erreur chargement {model_name}: {e}")
            else:
                logger.warning(f"  âš ï¸ Fichier modÃ¨le introuvable: {model_path}")
        
        logger.info(f"ğŸ“Š ModÃ¨les chargÃ©s: {list(self.models.keys())}")
    
    def _load_preprocessors(self):
        """Charge les prÃ©processeurs (scaler et encodeurs)"""
        logger.info("ğŸ”§ Chargement des prÃ©processeurs...")
        
        # Charger le scaler
        if SCALER_PATH.exists():
            try:
                self.scaler = joblib.load(SCALER_PATH)
                logger.info(f"  âœ… Scaler chargÃ© depuis {SCALER_PATH}")
            except Exception as e:
                logger.warning(f"  âš ï¸ Erreur chargement scaler: {e}")
        else:
            logger.warning(f"  âš ï¸ Fichier scaler introuvable: {SCALER_PATH}")
        
        # Charger les label encoders
        if LABEL_ENCODERS_PATH.exists():
            try:
                self.label_encoders = joblib.load(LABEL_ENCODERS_PATH)
                logger.info(f"  âœ… Label encoders chargÃ©s depuis {LABEL_ENCODERS_PATH}")
                logger.info(f"  ğŸ“‹ Encodeurs disponibles: {list(self.label_encoders.keys())}")
            except Exception as e:
                logger.warning(f"  âš ï¸ Erreur chargement label encoders: {e}")
        else:
            logger.warning(f"  âš ï¸ Fichier label encoders introuvable: {LABEL_ENCODERS_PATH}")
    
    def _create_ensemble_classifier(self):
        """CrÃ©e le classificateur d'ensemble"""
        logger.info("ğŸ¯ CrÃ©ation du classificateur d'ensemble...")
        
        if not self.models:
            logger.error("Aucun modÃ¨le disponible pour l'ensemble")
            return
        
        # CrÃ©er l'ensemble
        self.ensemble_classifier = AdvancedEnsembleClassifier()
        
        # Ajouter tous les modÃ¨les chargÃ©s
        for model_name, model in self.models.items():
            self.ensemble_classifier.add_model(model_name, model)
        
        # DÃ©finir les poids des modÃ¨les (depuis la configuration)
        weights = {}
        for model_name in self.models.keys():
            if model_name in MODELS_CONFIG:
                weights[model_name] = MODELS_CONFIG[model_name]["weight"]
        
        if weights:
            self.ensemble_classifier.set_model_weights(weights)
            logger.info(f"  âš–ï¸ Poids dÃ©finis: {weights}")
        
        # Marquer comme fitted (modÃ¨les prÃ©-entraÃ®nÃ©s)
        self.ensemble_classifier.is_fitted = True
        
        logger.info("  âœ… Ensemble classifier crÃ©Ã©")
    
    def _create_hybrid_system(self):
        """CrÃ©e le systÃ¨me hybride"""
        logger.info("ğŸ”¬ CrÃ©ation du systÃ¨me hybride...")
        
        if not self.ensemble_classifier:
            logger.error("Ensemble classifier non disponible pour le systÃ¨me hybride")
            return
        
        # CrÃ©er un dÃ©tecteur d'anomalies simple (peut Ãªtre amÃ©liorÃ©)
        anomaly_detector = IsolationForest(
            contamination=0.1,
            random_state=42,
            n_jobs=-1
        )
        
        # Note: Dans un vrai systÃ¨me, ce dÃ©tecteur devrait Ãªtre prÃ©-entraÃ®nÃ©
        # Pour l'instant, il sera entraÃ®nÃ© Ã  la volÃ©e avec les donnÃ©es normales
        
        # CrÃ©er le systÃ¨me hybride
        self.hybrid_system = HybridDetectionSystem(
            ensemble_classifier=self.ensemble_classifier,
            anomaly_detector=anomaly_detector,
            threshold=0.6
        )
        
        logger.info("  âœ… SystÃ¨me hybride crÃ©Ã©")
    
    def _initialize_preprocessor(self):
        """Initialise le prÃ©processeur temps rÃ©el"""
        logger.info("âš™ï¸ Initialisation du prÃ©processeur...")
        
        self.preprocessor = RealtimePreprocessor(
            scaler=self.scaler,
            label_encoders=self.label_encoders
        )
        
        logger.info("  âœ… PrÃ©processeur initialisÃ©")
    
    def get_model_info(self) -> Dict[str, Any]:
        """Retourne des informations sur les modÃ¨les chargÃ©s"""
        return {
            "models_loaded": list(self.models.keys()),
            "models_count": len(self.models),
            "scaler_available": self.scaler is not None,
            "label_encoders_available": list(self.label_encoders.keys()),
            "ensemble_available": self.ensemble_classifier is not None,
            "hybrid_available": self.hybrid_system is not None,
            "preprocessor_available": self.preprocessor is not None,
            "is_ready": self.is_loaded
        }
    
    def predict(self, data, strategy: str = "ensemble") -> Dict[str, Any]:
        """
        MÃ©thode principale de prÃ©diction - compatible avec le format attendu par FastAPI
        """
        if not self.is_loaded:
            raise RuntimeError("ModÃ¨les non chargÃ©s")
        
        try:
            # Si c'est un DataFrame d'une seule ligne
            if hasattr(data, 'shape') and data.shape[0] == 1:
                # Convertir en array numpy
                if hasattr(data, 'values'):
                    processed_data = data.values[0]
                else:
                    processed_data = data[0]
            else:
                processed_data = data
            
            # Faire la prÃ©diction avec l'ensemble
            if strategy == "ensemble" and self.ensemble_classifier:
                prediction = self.ensemble_classifier.predict([processed_data])[0]
                probabilities = self.ensemble_classifier.predict_proba([processed_data])[0]
                
                # Obtenir les prÃ©dictions individuelles
                individual_predictions = {}
                for model_name, model in self.models.items():
                    try:
                        pred = model.predict([processed_data])[0]
                        individual_predictions[model_name] = float(pred)
                    except Exception as e:
                        logger.warning(f"Erreur prÃ©diction {model_name}: {e}")
                        individual_predictions[model_name] = 0.0
                
            elif strategy == "hybrid" and self.hybrid_system:
                prediction = self.hybrid_system.predict([processed_data], strategy="hybrid")[0]
                probabilities = self.ensemble_classifier.predict_proba([processed_data])[0] if self.ensemble_classifier else [0.5, 0.5]
                individual_predictions = {"hybrid": float(prediction)}
            else:
                raise ValueError(f"StratÃ©gie inconnue ou non disponible: {strategy}")
            
            # Calculer les mÃ©triques
            attack_probability = float(probabilities[1]) if len(probabilities) > 1 else 0.5
            confidence = max(probabilities) if probabilities is not None else 0.5
            is_attack = bool(prediction == 1)
            
            return {
                "is_attack": is_attack,
                "confidence": float(confidence),
                "attack_probability": attack_probability,
                "individual_predictions": individual_predictions,
                "prediction": int(prediction)
            }
            
        except Exception as e:
            logger.error(f"Erreur prÃ©diction: {e}")
            return {
                "is_attack": False,
                "confidence": 0.0,
                "attack_probability": 0.0,
                "individual_predictions": {},
                "prediction": 0,
                "error": str(e)
            }

    def predict_single(self, log_data: str, strategy: str = "hybrid") -> Dict[str, Any]:
        """
        Fait une prÃ©diction sur une ligne de log
        """
        if not self.is_loaded:
            raise RuntimeError("ModÃ¨les non chargÃ©s")
        
        try:
            # 1. Parser les donnÃ©es
            parsed_data = self.preprocessor.parse_log_line(log_data)
            
            # 2. Valider les donnÃ©es
            if not self.preprocessor.validate_input(parsed_data):
                raise ValueError("DonnÃ©es d'entrÃ©e invalides")
            
            # 3. PrÃ©processer
            processed_data = self.preprocessor.preprocess_single_sample(parsed_data)
            
            # 4. Faire la prÃ©diction
            if strategy == "ensemble":
                prediction = self.ensemble_classifier.predict([processed_data])[0]
                probabilities = self.ensemble_classifier.predict_proba([processed_data])[0]
            elif strategy == "hybrid":
                prediction = self.hybrid_system.predict([processed_data], strategy="hybrid")[0]
                probabilities = self.ensemble_classifier.predict_proba([processed_data])[0]
            else:
                raise ValueError(f"StratÃ©gie inconnue: {strategy}")
            
            # 5. Calculer la confiance
            confidence = max(probabilities) if probabilities is not None else 0.5
            
            # 6. DÃ©terminer le label
            label = "Attack" if prediction == 1 else "Normal"
            
            return {
                "prediction": int(prediction),
                "label": label,
                "confidence": float(confidence),
                "probabilities": {
                    "normal": float(probabilities[0]) if probabilities is not None else 0.5,
                    "attack": float(probabilities[1]) if probabilities is not None else 0.5
                },
                "strategy": strategy,
                "status": "success"
            }
            
        except Exception as e:
            logger.error(f"Erreur prÃ©diction: {e}")
            return {
                "prediction": -1,
                "label": "Error",
                "confidence": 0.0,
                "error": str(e),
                "status": "error"
            }
    
    def predict_batch(self, log_data_list: list, strategy: str = "hybrid") -> list:
        """
        Fait des prÃ©dictions sur un batch de donnÃ©es
        """
        results = []
        for log_data in log_data_list:
            result = self.predict_single(log_data, strategy)
            results.append(result)
        return results
